2025-12-16 11:50:57 [INFO] [__main__:310] ================================================================================
2025-12-16 11:50:57 [INFO] [__main__:311] STAGE 5: MODEL TRAINING
2025-12-16 11:50:57 [INFO] [__main__:312] ================================================================================
2025-12-16 11:50:57 [INFO] [__main__:313] Project root: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc
2025-12-16 11:50:57 [INFO] [__main__:314] Scaled metadata: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-16 11:50:57 [INFO] [__main__:315] Features Stage 2: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage2/features_metadata.arrow
2025-12-16 11:50:57 [INFO] [__main__:316] Features Stage 4: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage4/features_scaled_metadata.arrow
2025-12-16 11:50:57 [INFO] [__main__:317] Model types: ['xgboost_vit_transformer']
2025-12-16 11:50:57 [INFO] [__main__:318] K-fold splits: 5
2025-12-16 11:50:57 [INFO] [__main__:319] Number of frames: 1000
2025-12-16 11:50:57 [INFO] [__main__:320] Output directory: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-16 11:50:57 [INFO] [__main__:321] Experiment tracking: Enabled
2025-12-16 11:50:57 [INFO] [__main__:324] Delete existing: False
2025-12-16 11:50:57 [INFO] [__main__:325] Resume mode: True
2025-12-16 11:50:57 [INFO] [__main__:326] Log file: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/logs/stage5_training_1765903857.log
2025-12-16 11:50:57 [INFO] [__main__:333] ================================================================================
2025-12-16 11:50:57 [INFO] [__main__:334] Checking prerequisites...
2025-12-16 11:50:57 [INFO] [__main__:335] ================================================================================
2025-12-16 11:50:57 [INFO] [__main__:342] ✓ Scaled metadata file found: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-16 11:50:57 [INFO] [__main__:352] ✓ All model types are valid
2025-12-16 11:50:57 [INFO] [__main__:358] ================================================================================
2025-12-16 11:50:57 [INFO] [__main__:359] Initial memory statistics:
2025-12-16 11:50:57 [INFO] [__main__:360] ================================================================================
2025-12-16 11:50:57 [INFO] [lib.utils.memory:91] Memory stats (Stage 5: before training): {'cpu_memory_mb': 735.92578125, 'cpu_memory_gb': 0.7186775207519531, 'cpu_vms_mb': 10217.69140625, 'gpu_allocated_gb': 0.0, 'gpu_reserved_gb': 0.0, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 16.928342016}
2025-12-16 11:50:57 [INFO] [__main__:364] ================================================================================
2025-12-16 11:50:57 [INFO] [__main__:365] Starting Stage 5: Model Training
2025-12-16 11:50:57 [INFO] [__main__:366] ================================================================================
2025-12-16 11:50:57 [INFO] [__main__:367] Training 1 model(s) with 5-fold cross-validation
2025-12-16 11:50:57 [INFO] [__main__:368] This may take a while depending on dataset size and model complexity...
2025-12-16 11:50:57 [INFO] [__main__:369] Progress will be logged in real-time
2025-12-16 11:50:57 [INFO] [__main__:370] ================================================================================
2025-12-16 11:50:57 [INFO] [__main__:375] Calling Stage 5 training pipeline...
2025-12-16 11:50:57 [INFO] [__main__:376] This may take a while - progress will be logged in real-time
2025-12-16 11:50:58 [INFO] [lib.training.pipeline:1443] Applied global PyTorch memory optimizations at pipeline start
2025-12-16 11:50:58 [INFO] [lib.training.pipeline:1446] ================================================================================
2025-12-16 11:50:58 [INFO] [lib.training.pipeline:1447] Stage 5: Model Training Pipeline Started
2025-12-16 11:50:58 [INFO] [lib.training.pipeline:1448] ================================================================================
2025-12-16 11:50:58 [INFO] [lib.training.pipeline:1449] Model types: ['xgboost_vit_transformer']
2025-12-16 11:50:58 [INFO] [lib.training.pipeline:1450] K-fold splits: 5
2025-12-16 11:50:58 [INFO] [lib.training.pipeline:1451] Frames per video: 1000
2025-12-16 11:50:58 [INFO] [lib.training.pipeline:1452] Output directory: data/stage5
2025-12-16 11:50:58 [INFO] [lib.training.pipeline:1453] Initializing pipeline...
2025-12-16 11:50:58 [INFO] [lib.training.pipeline:246] ================================================================================
2025-12-16 11:50:58 [INFO] [lib.training.pipeline:247] STAGE 5 PREREQUISITE VALIDATION
2025-12-16 11:50:58 [INFO] [lib.training.pipeline:248] ================================================================================
2025-12-16 11:50:58 [INFO] [lib.training.pipeline:250] 
[1/3] Checking Stage 3 (scaled videos) - REQUIRED for all models...
2025-12-16 11:51:01 [INFO] [lib.training.pipeline:259] ✓ Stage 3 metadata found: 3278 scaled videos
2025-12-16 11:51:01 [INFO] [lib.training.pipeline:260]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-16 11:51:01 [INFO] [lib.training.pipeline:262] 
[2/3] Checking Stage 2 (features) - REQUIRED for *_stage2 models...
2025-12-16 11:51:01 [INFO] [lib.training.pipeline:270] ✓ Stage 2 metadata found: 3278 feature rows
2025-12-16 11:51:01 [INFO] [lib.training.pipeline:271]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage2/features_metadata.arrow
2025-12-16 11:51:01 [INFO] [lib.training.pipeline:273] 
[3/3] Checking Stage 4 (scaled features) - REQUIRED for *_stage2_stage4 models...
2025-12-16 11:51:01 [INFO] [lib.training.pipeline:281] ✓ Stage 4 metadata found: 3277 feature rows
2025-12-16 11:51:01 [INFO] [lib.training.pipeline:282]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage4/features_scaled_metadata.arrow
2025-12-16 11:51:01 [INFO] [lib.training.pipeline:284] 
================================================================================
2025-12-16 11:51:01 [INFO] [lib.training.pipeline:285] MODEL REQUIREMENTS CHECK
2025-12-16 11:51:01 [INFO] [lib.training.pipeline:286] ================================================================================
2025-12-16 11:51:01 [INFO] [lib.training.pipeline:305] ✓ xgboost_vit_transformer: CAN RUN
2025-12-16 11:51:01 [INFO] [lib.training.pipeline:307] 
================================================================================
2025-12-16 11:51:01 [INFO] [lib.training.pipeline:308] VALIDATION SUMMARY
2025-12-16 11:51:01 [INFO] [lib.training.pipeline:309] ================================================================================
2025-12-16 11:51:01 [INFO] [lib.training.pipeline:310] Stage 3 (scaled videos): ✓ Available
2025-12-16 11:51:01 [INFO] [lib.training.pipeline:311]   Count: 3278 videos
2025-12-16 11:51:01 [INFO] [lib.training.pipeline:312] Stage 2 (features): ✓ Available
2025-12-16 11:51:01 [INFO] [lib.training.pipeline:313]   Count: 3278 feature rows
2025-12-16 11:51:01 [INFO] [lib.training.pipeline:314] Stage 4 (scaled features): ✓ Available
2025-12-16 11:51:01 [INFO] [lib.training.pipeline:315]   Count: 3277 feature rows
2025-12-16 11:51:01 [INFO] [lib.training.pipeline:316] 
Runnable models: 1/1
2025-12-16 11:51:01 [INFO] [lib.training.pipeline:317]   ['xgboost_vit_transformer']
2025-12-16 11:51:01 [INFO] [lib.training.pipeline:324] ================================================================================
2025-12-16 11:51:02 [INFO] [lib.training.pipeline:1534] 
Stage 5: Loading metadata...
2025-12-16 11:51:02 [INFO] [lib.training.pipeline:1558] Loaded metadata: 3278 rows
2025-12-16 11:51:02 [INFO] [lib.training.pipeline:1568] ✓ Data validation passed: 3278 rows (> 3000 required)
2025-12-16 11:51:02 [WARNING] [lib.utils.guardrails:171] Disk usage high: free=790924.11GB, used=1708915.89GB (68.4%)
2025-12-16 11:51:02 [INFO] [lib.training.pipeline:1589] Loading Stage 2 and Stage 4 features (required for feature-based models)...
2025-12-16 11:51:02 [INFO] [lib.training.pipeline:1599] Stage 5: Found 3278 scaled videos
2025-12-16 11:51:02 [INFO] [lib.training.pipeline:1602] ================================================================================
2025-12-16 11:51:02 [INFO] [lib.training.pipeline:1603] STAGE 5: VALIDATING VIDEOS (checking for corruption and empty videos)
2025-12-16 11:51:02 [INFO] [lib.training.pipeline:1604] ================================================================================
2025-12-16 11:51:02 [INFO] [lib.data.loading:156] Checking file existence for 3278 videos...
2025-12-16 11:51:06 [INFO] [lib.data.loading:166] Found 3278 existing video files (filtered out 0 missing files)
2025-12-16 11:51:06 [INFO] [lib.data.loading:170] Checking for corrupted videos (moov atom errors, etc.)...
2025-12-16 11:51:07 [INFO] [lib.data.loading:92] Loaded validation cache from /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/.video_validation_cache/validation_0192be168a40eb7e_corruptTrue_framesTrue.parquet (3278 entries)
2025-12-16 11:51:07 [INFO] [lib.data.loading:194] Cache hit: 3278 videos, Cache miss: 0 videos
2025-12-16 11:51:08 [WARNING] [lib.data.loading:306] Filtered out 1 corrupted videos and 0 empty videos. Keeping 3277 valid videos.
2025-12-16 11:51:08 [WARNING] [lib.data.loading:311] Sample of invalid videos:
2025-12-16 11:51:08 [WARNING] [lib.data.loading:313]   data/scaled_videos/FX5aeuJFQ64_aug1_scaled_aug1.mp4: Corrupted video: moov atom not found
2025-12-16 11:51:08 [INFO] [lib.data.loading:323] Found /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/skip_frame_check.txt - skipping frame check as requested.
2025-12-16 11:51:08 [WARNING] [lib.data.loading:387] Filtered out 1 invalid videos (corrupted). Keeping 3277 valid videos.
2025-12-16 11:51:08 [INFO] [lib.training.pipeline:1613] ✓ Video validation complete: 3277 valid videos ready for training
2025-12-16 11:51:08 [INFO] [lib.training.pipeline:1614] ================================================================================
2025-12-16 11:51:08 [INFO] [lib.training.pipeline:1700] Frame caching enabled (default): cache_dir=data/.frame_cache. This will cache processed frames to disk to speed up training. First epoch will be slower (building cache), subsequent epochs will be faster. To disable, set FVC_USE_FRAME_CACHE=0
2025-12-16 11:51:08 [INFO] [lib.training.pipeline:1773] Overriding num_frames to 400 for xgboost_vit_transformer. Original num_frames was 1000.
2025-12-16 11:51:08 [INFO] [lib.training.pipeline:1816] 
================================================================================
2025-12-16 11:51:08 [INFO] [lib.training.pipeline:1817] Stage 5: Training model: xgboost_vit_transformer
2025-12-16 11:51:08 [INFO] [lib.training.pipeline:1818] ================================================================================
2025-12-16 11:51:08 [INFO] [lib.training.pipeline:1836] Overriding model_config num_frames to 400 for xgboost_vit_transformer (XGBoost pretrained model with enhanced feature extraction) to improve feature quality.
2025-12-16 11:51:08 [INFO] [lib.training.pipeline:1854] Grid search: 1 hyperparameter combinations to try
2025-12-16 11:51:08 [INFO] [lib.training.pipeline:1862] ================================================================================
2025-12-16 11:51:08 [INFO] [lib.training.pipeline:1863] HYPERPARAMETER SEARCH: Using 10.0% stratified sample for efficiency
2025-12-16 11:51:08 [INFO] [lib.training.pipeline:1864] ================================================================================
2025-12-16 11:51:09 [INFO] [lib.training.pipeline:1873] Hyperparameter search sample: 327 rows (10.0% of 3277 total)
2025-12-16 11:51:09 [INFO] [lib.training.pipeline:1874] To change sample size, set FVC_GRID_SEARCH_SAMPLE_SIZE environment variable (current: 0.1)
2025-12-16 11:51:09 [INFO] [lib.training.pipeline:1886] Using 5-fold stratified cross-validation on 10.0% sample for hyperparameter search
2025-12-16 11:51:09 [INFO] [lib.training.pipeline:1897] 
================================================================================
2025-12-16 11:51:09 [INFO] [lib.training.pipeline:1898] Grid Search: Hyperparameter combination 1/1
2025-12-16 11:51:09 [INFO] [lib.training.pipeline:1899] Parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8}
2025-12-16 11:51:09 [INFO] [lib.training.pipeline:1900] ================================================================================
2025-12-16 11:51:09 [INFO] [lib.training.pipeline:1918] 
Hyperparameter Search - xgboost_vit_transformer - Fold 1/5 (10.0% sample)
2025-12-16 11:51:09 [INFO] [lib.training.pipeline:448] Training XGBoost model xgboost_vit_transformer on fold 1...
2025-12-16 11:51:09 [INFO] [lib.training._xgboost_pretrained:636] Training XGBoost on features from vit_transformer...
2025-12-16 11:51:09 [INFO] [lib.training._xgboost_pretrained:637] Processing 261 videos...
2025-12-16 11:51:09 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_transformer (num_frames=400)
2025-12-16 11:51:21 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-16 11:51:26 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-16 11:51:27 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-16 11:51:28 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_transformer model to GPU, cleared cache
2025-12-16 11:51:28 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_transformer) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-16 11:51:29 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_transformer (num_frames=400)...
2025-12-16 11:51:29 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-16 12:09:22 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (261, 3072)
2025-12-16 12:09:22 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_transformer model from GPU after feature extraction
2025-12-16 12:09:22 [INFO] [lib.training._xgboost_pretrained:660] Removing collinear features...
2025-12-16 12:09:22 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-16 12:09:24 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-16 12:09:24 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-16 12:09:24 [INFO] [lib.training._xgboost_pretrained:667] Using 3072 features after collinearity removal
2025-12-16 12:09:24 [INFO] [lib.training._xgboost_pretrained:683] Class distribution: Class 0=128, Class 1=133, scale_pos_weight=0.962
2025-12-16 12:09:24 [INFO] [lib.training._xgboost_pretrained:701] Training XGBoost: 208 train samples, 53 validation samples for early stopping
2025-12-16 12:09:24 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-16 12:09:34 [INFO] [lib.training._xgboost_pretrained:770] Early stopping: Best iteration = 200 (out of 200)
2025-12-16 12:09:34 [INFO] [lib.training._xgboost_pretrained:772] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-16 12:09:34 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_transformer (num_frames=400)
2025-12-16 12:09:35 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-16 12:09:35 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-16 12:09:35 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-16 12:09:36 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_transformer model to GPU, cleared cache
2025-12-16 12:09:36 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_transformer) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-16 12:09:36 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_transformer (num_frames=400)...
2025-12-16 12:09:36 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-16 12:14:17 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (66, 3072)
2025-12-16 12:14:18 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_transformer model from GPU after feature extraction
2025-12-16 12:14:18 [INFO] [lib.training.pipeline:500] Fold 1 - Val Loss: 0.4664, Val Acc: 0.7727, Val F1: 0.7692, Val Precision: 0.8065, Val Recall: 0.7353
2025-12-16 12:14:18 [INFO] [lib.training.pipeline:505]   Class 0 - Precision: 0.7429, Recall: 0.8125, F1: 0.7761
2025-12-16 12:14:18 [INFO] [lib.training.pipeline:509]   Class 1 - Precision: 0.8065, Recall: 0.7353, F1: 0.7692
2025-12-16 12:14:18 [INFO] [lib.training._xgboost_pretrained:840] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_transformer/fold_1
2025-12-16 12:14:18 [INFO] [lib.training.pipeline:516] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_transformer/fold_1
2025-12-16 12:14:21 [INFO] [lib.training.visualization:480] Generated fold 1 plots: ROC/PR curves and confusion matrix
2025-12-16 12:14:21 [INFO] [lib.training.pipeline:1918] 
Hyperparameter Search - xgboost_vit_transformer - Fold 2/5 (10.0% sample)
2025-12-16 12:14:21 [INFO] [lib.training.pipeline:448] Training XGBoost model xgboost_vit_transformer on fold 2...
2025-12-16 12:14:21 [INFO] [lib.training._xgboost_pretrained:636] Training XGBoost on features from vit_transformer...
2025-12-16 12:14:21 [INFO] [lib.training._xgboost_pretrained:637] Processing 261 videos...
2025-12-16 12:14:22 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_transformer (num_frames=400)
2025-12-16 12:14:23 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-16 12:14:23 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-16 12:14:23 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-16 12:14:23 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_transformer model to GPU, cleared cache
2025-12-16 12:14:23 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_transformer) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-16 12:14:23 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_transformer (num_frames=400)...
2025-12-16 12:14:23 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-16 12:33:35 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (261, 3072)
2025-12-16 12:33:35 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_transformer model from GPU after feature extraction
2025-12-16 12:33:36 [INFO] [lib.training._xgboost_pretrained:660] Removing collinear features...
2025-12-16 12:33:36 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-16 12:33:37 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-16 12:33:37 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-16 12:33:37 [INFO] [lib.training._xgboost_pretrained:667] Using 3072 features after collinearity removal
2025-12-16 12:33:37 [INFO] [lib.training._xgboost_pretrained:683] Class distribution: Class 0=128, Class 1=133, scale_pos_weight=0.962
2025-12-16 12:33:37 [INFO] [lib.training._xgboost_pretrained:701] Training XGBoost: 208 train samples, 53 validation samples for early stopping
2025-12-16 12:33:37 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-16 12:33:45 [INFO] [lib.training._xgboost_pretrained:770] Early stopping: Best iteration = 172 (out of 200)
2025-12-16 12:33:45 [INFO] [lib.training._xgboost_pretrained:772] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-16 12:33:46 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_transformer (num_frames=400)
2025-12-16 12:33:47 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-16 12:33:47 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-16 12:33:47 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-16 12:33:47 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_transformer model to GPU, cleared cache
2025-12-16 12:33:47 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_transformer) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-16 12:33:47 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_transformer (num_frames=400)...
2025-12-16 12:33:47 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-16 12:38:35 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (66, 3072)
2025-12-16 12:38:36 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_transformer model from GPU after feature extraction
2025-12-16 12:38:36 [INFO] [lib.training.pipeline:500] Fold 2 - Val Loss: 0.3902, Val Acc: 0.7879, Val F1: 0.7879, Val Precision: 0.8125, Val Recall: 0.7647
2025-12-16 12:38:36 [INFO] [lib.training.pipeline:505]   Class 0 - Precision: 0.7647, Recall: 0.8125, F1: 0.7879
2025-12-16 12:38:36 [INFO] [lib.training.pipeline:509]   Class 1 - Precision: 0.8125, Recall: 0.7647, F1: 0.7879
2025-12-16 12:38:36 [INFO] [lib.training._xgboost_pretrained:840] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_transformer/fold_2
2025-12-16 12:38:36 [INFO] [lib.training.pipeline:516] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_transformer/fold_2
2025-12-16 12:38:37 [INFO] [lib.training.visualization:480] Generated fold 2 plots: ROC/PR curves and confusion matrix
2025-12-16 12:38:37 [INFO] [lib.training.pipeline:1918] 
Hyperparameter Search - xgboost_vit_transformer - Fold 3/5 (10.0% sample)
2025-12-16 12:38:37 [INFO] [lib.training.pipeline:448] Training XGBoost model xgboost_vit_transformer on fold 3...
2025-12-16 12:38:37 [INFO] [lib.training._xgboost_pretrained:636] Training XGBoost on features from vit_transformer...
2025-12-16 12:38:37 [INFO] [lib.training._xgboost_pretrained:637] Processing 262 videos...
2025-12-16 12:38:38 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_transformer (num_frames=400)
2025-12-16 12:38:39 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-16 12:38:39 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-16 12:38:39 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-16 12:38:39 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_transformer model to GPU, cleared cache
2025-12-16 12:38:39 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_transformer) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-16 12:38:39 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_transformer (num_frames=400)...
2025-12-16 12:38:39 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-16 12:57:29 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (262, 3072)
2025-12-16 12:57:30 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_transformer model from GPU after feature extraction
2025-12-16 12:57:30 [INFO] [lib.training._xgboost_pretrained:660] Removing collinear features...
2025-12-16 12:57:30 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-16 12:57:31 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-16 12:57:31 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-16 12:57:31 [INFO] [lib.training._xgboost_pretrained:667] Using 3072 features after collinearity removal
2025-12-16 12:57:31 [INFO] [lib.training._xgboost_pretrained:683] Class distribution: Class 0=128, Class 1=134, scale_pos_weight=0.955
2025-12-16 12:57:31 [INFO] [lib.training._xgboost_pretrained:701] Training XGBoost: 209 train samples, 53 validation samples for early stopping
2025-12-16 12:57:31 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-16 12:57:35 [INFO] [lib.training._xgboost_pretrained:770] Early stopping: Best iteration = 32 (out of 200)
2025-12-16 12:57:35 [INFO] [lib.training._xgboost_pretrained:772] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-16 12:57:35 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_transformer (num_frames=400)
2025-12-16 12:57:36 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-16 12:57:36 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-16 12:57:36 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-16 12:57:37 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_transformer model to GPU, cleared cache
2025-12-16 12:57:37 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_transformer) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-16 12:57:37 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_transformer (num_frames=400)...
2025-12-16 12:57:37 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-16 13:02:05 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (65, 3072)
2025-12-16 13:02:05 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_transformer model from GPU after feature extraction
2025-12-16 13:02:05 [INFO] [lib.training.pipeline:500] Fold 3 - Val Loss: 0.5288, Val Acc: 0.7385, Val F1: 0.7213, Val Precision: 0.7857, Val Recall: 0.6667
2025-12-16 13:02:05 [INFO] [lib.training.pipeline:505]   Class 0 - Precision: 0.7027, Recall: 0.8125, F1: 0.7536
2025-12-16 13:02:05 [INFO] [lib.training.pipeline:509]   Class 1 - Precision: 0.7857, Recall: 0.6667, F1: 0.7213
2025-12-16 13:02:05 [INFO] [lib.training._xgboost_pretrained:840] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_transformer/fold_3
2025-12-16 13:02:05 [INFO] [lib.training.pipeline:516] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_transformer/fold_3
2025-12-16 13:02:06 [INFO] [lib.training.visualization:480] Generated fold 3 plots: ROC/PR curves and confusion matrix
2025-12-16 13:02:07 [INFO] [lib.training.pipeline:1918] 
Hyperparameter Search - xgboost_vit_transformer - Fold 4/5 (10.0% sample)
2025-12-16 13:02:07 [INFO] [lib.training.pipeline:448] Training XGBoost model xgboost_vit_transformer on fold 4...
2025-12-16 13:02:07 [INFO] [lib.training._xgboost_pretrained:636] Training XGBoost on features from vit_transformer...
2025-12-16 13:02:07 [INFO] [lib.training._xgboost_pretrained:637] Processing 262 videos...
2025-12-16 13:02:07 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_transformer (num_frames=400)
2025-12-16 13:02:08 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-16 13:02:08 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-16 13:02:08 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-16 13:02:08 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_transformer model to GPU, cleared cache
2025-12-16 13:02:08 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_transformer) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-16 13:02:09 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_transformer (num_frames=400)...
2025-12-16 13:02:09 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-16 13:19:53 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (262, 3072)
2025-12-16 13:19:54 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_transformer model from GPU after feature extraction
2025-12-16 13:19:54 [INFO] [lib.training._xgboost_pretrained:660] Removing collinear features...
2025-12-16 13:19:54 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-16 13:19:55 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-16 13:19:55 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-16 13:19:55 [INFO] [lib.training._xgboost_pretrained:667] Using 3072 features after collinearity removal
2025-12-16 13:19:55 [INFO] [lib.training._xgboost_pretrained:683] Class distribution: Class 0=128, Class 1=134, scale_pos_weight=0.955
2025-12-16 13:19:55 [INFO] [lib.training._xgboost_pretrained:701] Training XGBoost: 209 train samples, 53 validation samples for early stopping
2025-12-16 13:19:55 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-16 13:20:00 [INFO] [lib.training._xgboost_pretrained:770] Early stopping: Best iteration = 51 (out of 200)
2025-12-16 13:20:00 [INFO] [lib.training._xgboost_pretrained:772] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-16 13:20:00 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_transformer (num_frames=400)
2025-12-16 13:20:01 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-16 13:20:02 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-16 13:20:02 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-16 13:20:02 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_transformer model to GPU, cleared cache
2025-12-16 13:20:02 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_transformer) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-16 13:20:02 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_transformer (num_frames=400)...
2025-12-16 13:20:02 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-16 13:24:31 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (65, 3072)
2025-12-16 13:24:32 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_transformer model from GPU after feature extraction
2025-12-16 13:24:32 [INFO] [lib.training.pipeline:500] Fold 4 - Val Loss: 0.4936, Val Acc: 0.7846, Val F1: 0.7941, Val Precision: 0.7714, Val Recall: 0.8182
2025-12-16 13:24:32 [INFO] [lib.training.pipeline:505]   Class 0 - Precision: 0.8000, Recall: 0.7500, F1: 0.7742
2025-12-16 13:24:32 [INFO] [lib.training.pipeline:509]   Class 1 - Precision: 0.7714, Recall: 0.8182, F1: 0.7941
2025-12-16 13:24:32 [INFO] [lib.training._xgboost_pretrained:840] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_transformer/fold_4
2025-12-16 13:24:32 [INFO] [lib.training.pipeline:516] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_transformer/fold_4
2025-12-16 13:24:33 [INFO] [lib.training.visualization:480] Generated fold 4 plots: ROC/PR curves and confusion matrix
2025-12-16 13:24:34 [INFO] [lib.training.pipeline:1918] 
Hyperparameter Search - xgboost_vit_transformer - Fold 5/5 (10.0% sample)
2025-12-16 13:24:34 [INFO] [lib.training.pipeline:448] Training XGBoost model xgboost_vit_transformer on fold 5...
2025-12-16 13:24:34 [INFO] [lib.training._xgboost_pretrained:636] Training XGBoost on features from vit_transformer...
2025-12-16 13:24:34 [INFO] [lib.training._xgboost_pretrained:637] Processing 262 videos...
2025-12-16 13:24:34 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_transformer (num_frames=400)
2025-12-16 13:24:35 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-16 13:24:35 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-16 13:24:35 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-16 13:24:35 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_transformer model to GPU, cleared cache
2025-12-16 13:24:35 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_transformer) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-16 13:24:35 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_transformer (num_frames=400)...
2025-12-16 13:24:35 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-16 13:43:13 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (262, 3072)
2025-12-16 13:43:13 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_transformer model from GPU after feature extraction
2025-12-16 13:43:13 [INFO] [lib.training._xgboost_pretrained:660] Removing collinear features...
2025-12-16 13:43:13 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-16 13:43:14 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-16 13:43:14 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-16 13:43:14 [INFO] [lib.training._xgboost_pretrained:667] Using 3072 features after collinearity removal
2025-12-16 13:43:14 [INFO] [lib.training._xgboost_pretrained:683] Class distribution: Class 0=128, Class 1=134, scale_pos_weight=0.955
2025-12-16 13:43:14 [INFO] [lib.training._xgboost_pretrained:701] Training XGBoost: 209 train samples, 53 validation samples for early stopping
2025-12-16 13:43:14 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-16 13:43:22 [INFO] [lib.training._xgboost_pretrained:770] Early stopping: Best iteration = 111 (out of 200)
2025-12-16 13:43:22 [INFO] [lib.training._xgboost_pretrained:772] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-16 13:43:22 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_transformer (num_frames=400)
2025-12-16 13:43:23 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-16 13:43:23 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-16 13:43:23 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-16 13:43:24 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_transformer model to GPU, cleared cache
2025-12-16 13:43:24 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_transformer) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-16 13:43:24 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_transformer (num_frames=400)...
2025-12-16 13:43:24 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-16 13:47:35 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (65, 3072)
2025-12-16 13:47:35 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_transformer model from GPU after feature extraction
2025-12-16 13:47:35 [INFO] [lib.training.pipeline:500] Fold 5 - Val Loss: 0.4740, Val Acc: 0.7692, Val F1: 0.7692, Val Precision: 0.7812, Val Recall: 0.7576
2025-12-16 13:47:35 [INFO] [lib.training.pipeline:505]   Class 0 - Precision: 0.7576, Recall: 0.7812, F1: 0.7692
2025-12-16 13:47:35 [INFO] [lib.training.pipeline:509]   Class 1 - Precision: 0.7812, Recall: 0.7576, F1: 0.7692
2025-12-16 13:47:35 [INFO] [lib.training._xgboost_pretrained:840] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_transformer/fold_5
2025-12-16 13:47:35 [INFO] [lib.training.pipeline:516] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_transformer/fold_5
2025-12-16 13:47:37 [INFO] [lib.training.visualization:480] Generated fold 5 plots: ROC/PR curves and confusion matrix
2025-12-16 13:47:37 [INFO] [lib.training.pipeline:2079] Parameter combination 1 - Mean F1: 0.7684, Mean Acc: 0.7706
2025-12-16 13:47:37 [INFO] [lib.training.pipeline:2091] Using single parameter combination: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8}
2025-12-16 13:47:37 [INFO] [lib.training.pipeline:2094] ================================================================================
2025-12-16 13:47:37 [INFO] [lib.training.pipeline:2095] FINAL TRAINING: Using full dataset with best hyperparameters
2025-12-16 13:47:37 [INFO] [lib.training.pipeline:2096] ================================================================================
2025-12-16 13:47:37 [INFO] [lib.training.pipeline:2109] Final training: Using 5-fold stratified cross-validation on full dataset (3277 rows)
2025-12-16 13:47:37 [INFO] [lib.training.pipeline:2117] Final training using best hyperparameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8}
2025-12-16 13:47:37 [INFO] [lib.training.pipeline:2123] 
Final Training - xgboost_vit_transformer - Fold 1/5 (full dataset)
2025-12-16 13:47:37 [INFO] [lib.training.pipeline:448] Training XGBoost model xgboost_vit_transformer on fold 1...
2025-12-16 13:47:37 [INFO] [lib.training._xgboost_pretrained:636] Training XGBoost on features from vit_transformer...
2025-12-16 13:47:37 [INFO] [lib.training._xgboost_pretrained:637] Processing 2621 videos...
2025-12-16 13:47:37 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_transformer (num_frames=400)
2025-12-16 13:47:38 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-16 13:47:38 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-16 13:47:39 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-16 13:47:39 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_transformer model to GPU, cleared cache
2025-12-16 13:47:39 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_transformer) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-16 13:47:39 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_transformer (num_frames=400)...
2025-12-16 13:47:39 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-16 17:10:20 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (2621, 3072)
2025-12-16 17:10:20 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_transformer model from GPU after feature extraction
2025-12-16 17:10:20 [INFO] [lib.training._xgboost_pretrained:660] Removing collinear features...
2025-12-16 17:10:21 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-16 17:10:22 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-16 17:10:22 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-16 17:10:22 [INFO] [lib.training._xgboost_pretrained:667] Using 3072 features after collinearity removal
2025-12-16 17:10:22 [INFO] [lib.training._xgboost_pretrained:683] Class distribution: Class 0=1284, Class 1=1337, scale_pos_weight=0.960
2025-12-16 17:10:22 [INFO] [lib.training._xgboost_pretrained:701] Training XGBoost: 2096 train samples, 525 validation samples for early stopping
2025-12-16 17:10:22 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-16 17:11:21 [INFO] [lib.training._xgboost_pretrained:770] Early stopping: Best iteration = 200 (out of 200)
2025-12-16 17:11:21 [INFO] [lib.training._xgboost_pretrained:772] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-16 17:11:21 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_transformer (num_frames=400)
2025-12-16 17:11:22 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-16 17:11:22 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-16 17:11:22 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-16 17:11:23 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_transformer model to GPU, cleared cache
2025-12-16 17:11:23 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_transformer) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-16 17:11:23 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_transformer (num_frames=400)...
2025-12-16 17:11:23 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-16 17:55:20 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (656, 3072)
2025-12-16 17:55:21 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_transformer model from GPU after feature extraction
2025-12-16 17:55:21 [INFO] [lib.training.pipeline:500] Fold 1 - Val Loss: 0.0490, Val Acc: 0.9954, Val F1: 0.9955, Val Precision: 0.9970, Val Recall: 0.9940
2025-12-16 17:55:21 [INFO] [lib.training._xgboost_pretrained:840] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_transformer/fold_1
2025-12-16 17:55:21 [INFO] [lib.training.pipeline:516] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_transformer/fold_1
2025-12-16 17:55:22 [INFO] [lib.training.visualization:480] Generated fold 1 plots: ROC/PR curves and confusion matrix
2025-12-16 17:55:22 [INFO] [lib.training.pipeline:2123] 
Final Training - xgboost_vit_transformer - Fold 2/5 (full dataset)
2025-12-16 17:55:22 [INFO] [lib.training.pipeline:448] Training XGBoost model xgboost_vit_transformer on fold 2...
2025-12-16 17:55:22 [INFO] [lib.training._xgboost_pretrained:636] Training XGBoost on features from vit_transformer...
2025-12-16 17:55:22 [INFO] [lib.training._xgboost_pretrained:637] Processing 2621 videos...
2025-12-16 17:55:22 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_transformer (num_frames=400)
2025-12-16 17:55:23 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-16 17:55:23 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-16 17:55:23 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-16 17:55:24 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_transformer model to GPU, cleared cache
2025-12-16 17:55:24 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_transformer) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-16 17:55:24 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_transformer (num_frames=400)...
2025-12-16 17:55:24 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-16 21:14:20 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (2621, 3072)
2025-12-16 21:14:21 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_transformer model from GPU after feature extraction
2025-12-16 21:14:21 [INFO] [lib.training._xgboost_pretrained:660] Removing collinear features...
2025-12-16 21:14:21 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-16 21:14:23 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-16 21:14:23 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-16 21:14:23 [INFO] [lib.training._xgboost_pretrained:667] Using 3072 features after collinearity removal
2025-12-16 21:14:23 [INFO] [lib.training._xgboost_pretrained:683] Class distribution: Class 0=1284, Class 1=1337, scale_pos_weight=0.960
2025-12-16 21:14:23 [INFO] [lib.training._xgboost_pretrained:701] Training XGBoost: 2096 train samples, 525 validation samples for early stopping
2025-12-16 21:14:23 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-16 21:15:21 [INFO] [lib.training._xgboost_pretrained:770] Early stopping: Best iteration = 200 (out of 200)
2025-12-16 21:15:21 [INFO] [lib.training._xgboost_pretrained:772] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-16 21:15:22 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_transformer (num_frames=400)
2025-12-16 21:15:23 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-16 21:15:23 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-16 21:15:23 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-16 21:15:23 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_transformer model to GPU, cleared cache
2025-12-16 21:15:23 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_transformer) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-16 21:15:23 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_transformer (num_frames=400)...
2025-12-16 21:15:24 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-16 22:01:59 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (656, 3072)
2025-12-16 22:02:00 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_transformer model from GPU after feature extraction
2025-12-16 22:02:00 [INFO] [lib.training.pipeline:500] Fold 2 - Val Loss: 0.0429, Val Acc: 0.9970, Val F1: 0.9970, Val Precision: 0.9970, Val Recall: 0.9970
2025-12-16 22:02:00 [INFO] [lib.training._xgboost_pretrained:840] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_transformer/fold_2
2025-12-16 22:02:00 [INFO] [lib.training.pipeline:516] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_transformer/fold_2
2025-12-16 22:02:01 [INFO] [lib.training.visualization:480] Generated fold 2 plots: ROC/PR curves and confusion matrix
2025-12-16 22:02:01 [INFO] [lib.training.pipeline:2123] 
Final Training - xgboost_vit_transformer - Fold 3/5 (full dataset)
2025-12-16 22:02:01 [INFO] [lib.training.pipeline:448] Training XGBoost model xgboost_vit_transformer on fold 3...
2025-12-16 22:02:01 [INFO] [lib.training._xgboost_pretrained:636] Training XGBoost on features from vit_transformer...
2025-12-16 22:02:01 [INFO] [lib.training._xgboost_pretrained:637] Processing 2622 videos...
2025-12-16 22:02:02 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_transformer (num_frames=400)
2025-12-16 22:02:03 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-16 22:02:03 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-16 22:02:03 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-16 22:02:03 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_transformer model to GPU, cleared cache
2025-12-16 22:02:03 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_transformer) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-16 22:02:03 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_transformer (num_frames=400)...
2025-12-16 22:02:03 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-17 01:20:57 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (2622, 3072)
2025-12-17 01:20:58 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_transformer model from GPU after feature extraction
2025-12-17 01:20:58 [INFO] [lib.training._xgboost_pretrained:660] Removing collinear features...
2025-12-17 01:20:58 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-17 01:21:00 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-17 01:21:00 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-17 01:21:00 [INFO] [lib.training._xgboost_pretrained:667] Using 3072 features after collinearity removal
2025-12-17 01:21:00 [INFO] [lib.training._xgboost_pretrained:683] Class distribution: Class 0=1284, Class 1=1338, scale_pos_weight=0.960
2025-12-17 01:21:00 [INFO] [lib.training._xgboost_pretrained:701] Training XGBoost: 2097 train samples, 525 validation samples for early stopping
2025-12-17 01:21:00 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-17 01:21:58 [INFO] [lib.training._xgboost_pretrained:770] Early stopping: Best iteration = 200 (out of 200)
2025-12-17 01:21:58 [INFO] [lib.training._xgboost_pretrained:772] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-17 01:21:59 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_transformer (num_frames=400)
2025-12-17 01:22:00 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-17 01:22:00 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-17 01:22:00 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-17 01:22:00 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_transformer model to GPU, cleared cache
2025-12-17 01:22:00 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_transformer) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-17 01:22:00 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_transformer (num_frames=400)...
2025-12-17 01:22:01 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-17 02:08:02 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (655, 3072)
2025-12-17 02:08:03 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_transformer model from GPU after feature extraction
2025-12-17 02:08:03 [INFO] [lib.training.pipeline:500] Fold 3 - Val Loss: 0.0505, Val Acc: 0.9924, Val F1: 0.9925, Val Precision: 0.9940, Val Recall: 0.9910
2025-12-17 02:08:03 [INFO] [lib.training._xgboost_pretrained:840] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_transformer/fold_3
2025-12-17 02:08:03 [INFO] [lib.training.pipeline:516] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_transformer/fold_3
2025-12-17 02:08:05 [INFO] [lib.training.visualization:480] Generated fold 3 plots: ROC/PR curves and confusion matrix
2025-12-17 02:08:05 [INFO] [lib.training.pipeline:2123] 
Final Training - xgboost_vit_transformer - Fold 4/5 (full dataset)
2025-12-17 02:08:05 [INFO] [lib.training.pipeline:448] Training XGBoost model xgboost_vit_transformer on fold 4...
2025-12-17 02:08:05 [INFO] [lib.training._xgboost_pretrained:636] Training XGBoost on features from vit_transformer...
2025-12-17 02:08:05 [INFO] [lib.training._xgboost_pretrained:637] Processing 2622 videos...
2025-12-17 02:08:05 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_transformer (num_frames=400)
2025-12-17 02:08:06 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-17 02:08:06 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-17 02:08:06 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-17 02:08:07 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_transformer model to GPU, cleared cache
2025-12-17 02:08:07 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_transformer) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-17 02:08:07 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_transformer (num_frames=400)...
2025-12-17 02:08:07 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-17 05:07:06 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (2622, 3072)
2025-12-17 05:07:06 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_transformer model from GPU after feature extraction
2025-12-17 05:07:06 [INFO] [lib.training._xgboost_pretrained:660] Removing collinear features...
2025-12-17 05:07:07 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-17 05:07:08 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-17 05:07:08 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-17 05:07:08 [INFO] [lib.training._xgboost_pretrained:667] Using 3072 features after collinearity removal
2025-12-17 05:07:08 [INFO] [lib.training._xgboost_pretrained:683] Class distribution: Class 0=1284, Class 1=1338, scale_pos_weight=0.960
2025-12-17 05:07:08 [INFO] [lib.training._xgboost_pretrained:701] Training XGBoost: 2097 train samples, 525 validation samples for early stopping
2025-12-17 05:07:08 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-17 05:08:07 [INFO] [lib.training._xgboost_pretrained:770] Early stopping: Best iteration = 200 (out of 200)
2025-12-17 05:08:07 [INFO] [lib.training._xgboost_pretrained:772] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-17 05:08:07 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_transformer (num_frames=400)
2025-12-17 05:08:08 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-17 05:08:09 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-17 05:08:09 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-17 05:08:09 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_transformer model to GPU, cleared cache
2025-12-17 05:08:09 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_transformer) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-17 05:08:09 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_transformer (num_frames=400)...
2025-12-17 05:08:09 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-17 05:54:32 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (655, 3072)
2025-12-17 05:54:32 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_transformer model from GPU after feature extraction
2025-12-17 05:54:33 [INFO] [lib.training.pipeline:500] Fold 4 - Val Loss: 0.0447, Val Acc: 0.9969, Val F1: 0.9970, Val Precision: 0.9970, Val Recall: 0.9970
2025-12-17 05:54:33 [INFO] [lib.training._xgboost_pretrained:840] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_transformer/fold_4
2025-12-17 05:54:33 [INFO] [lib.training.pipeline:516] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_transformer/fold_4
2025-12-17 05:54:34 [INFO] [lib.training.visualization:480] Generated fold 4 plots: ROC/PR curves and confusion matrix
2025-12-17 05:54:34 [INFO] [lib.training.pipeline:2123] 
Final Training - xgboost_vit_transformer - Fold 5/5 (full dataset)
2025-12-17 05:54:34 [INFO] [lib.training.pipeline:448] Training XGBoost model xgboost_vit_transformer on fold 5...
2025-12-17 05:54:34 [INFO] [lib.training._xgboost_pretrained:636] Training XGBoost on features from vit_transformer...
2025-12-17 05:54:34 [INFO] [lib.training._xgboost_pretrained:637] Processing 2622 videos...
2025-12-17 05:54:34 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_transformer (num_frames=400)
2025-12-17 05:54:36 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-17 05:54:36 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-17 05:54:36 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-17 05:54:36 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_transformer model to GPU, cleared cache
2025-12-17 05:54:36 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_transformer) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-17 05:54:36 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_transformer (num_frames=400)...
2025-12-17 05:54:36 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-17 08:57:07 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (2622, 3072)
2025-12-17 08:57:08 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_transformer model from GPU after feature extraction
2025-12-17 08:57:08 [INFO] [lib.training._xgboost_pretrained:660] Removing collinear features...
2025-12-17 08:57:08 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-17 08:57:10 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-17 08:57:10 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-17 08:57:10 [INFO] [lib.training._xgboost_pretrained:667] Using 3072 features after collinearity removal
2025-12-17 08:57:10 [INFO] [lib.training._xgboost_pretrained:683] Class distribution: Class 0=1284, Class 1=1338, scale_pos_weight=0.960
2025-12-17 08:57:10 [INFO] [lib.training._xgboost_pretrained:701] Training XGBoost: 2097 train samples, 525 validation samples for early stopping
2025-12-17 08:57:10 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-17 08:58:08 [INFO] [lib.training._xgboost_pretrained:770] Early stopping: Best iteration = 200 (out of 200)
2025-12-17 08:58:08 [INFO] [lib.training._xgboost_pretrained:772] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-17 08:58:08 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_transformer (num_frames=400)
2025-12-17 08:58:10 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-17 08:58:10 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-17 08:58:10 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-17 08:58:10 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_transformer model to GPU, cleared cache
2025-12-17 08:58:10 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_transformer) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-17 08:58:10 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_transformer (num_frames=400)...
2025-12-17 08:58:11 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-17 09:43:20 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (655, 3072)
2025-12-17 09:43:21 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_transformer model from GPU after feature extraction
2025-12-17 09:43:21 [INFO] [lib.training.pipeline:500] Fold 5 - Val Loss: 0.0463, Val Acc: 0.9985, Val F1: 0.9985, Val Precision: 1.0000, Val Recall: 0.9970
2025-12-17 09:43:21 [INFO] [lib.training._xgboost_pretrained:840] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_transformer/fold_5
2025-12-17 09:43:21 [INFO] [lib.training.pipeline:516] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_transformer/fold_5
2025-12-17 09:43:22 [INFO] [lib.training.visualization:480] Generated fold 5 plots: ROC/PR curves and confusion matrix
2025-12-17 09:43:23 [INFO] [lib.training.pipeline:107] Saved best model from fold 5: Copied 2 model file(s) from fold_5 to best_model
2025-12-17 09:43:23 [INFO] [lib.training.pipeline:2348] 
xgboost_vit_transformer - Avg Val Loss: 0.0467 ± 0.0027, Avg Val Acc: 0.9960 ± 0.0021, Avg Val F1: 0.9961 ± 0.0020
2025-12-17 09:43:23 [INFO] [lib.training.pipeline:2352]   Avg Val Precision: 0.9970 ± 0.0019, Avg Val Recall: 0.9952 ± 0.0024
2025-12-17 09:43:23 [INFO] [lib.training.pipeline:2356]   Class 0 - F1: 0.9960 ± 0.0021, Precision: 0.9950 ± 0.0025, Recall: 0.9969 ± 0.0020
2025-12-17 09:43:23 [INFO] [lib.training.pipeline:2361]   Class 1 - F1: 0.9961 ± 0.0020, Precision: 0.9970 ± 0.0019, Recall: 0.9952 ± 0.0024
2025-12-17 09:43:23 [INFO] [lib.training.pipeline:2399] Saved aggregated metrics to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_transformer/metrics.json (model: xgboost_vit_transformer)
2025-12-17 09:43:25 [INFO] [lib.training.visualization:256] Saved CV fold comparison to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_transformer/plots/cv_fold_comparison.png
2025-12-17 09:43:25 [INFO] [lib.training.pipeline:2426] Generated plots for xgboost_vit_transformer in /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_transformer/plots
2025-12-17 09:43:26 [INFO] [lib.training.pipeline:2463] ================================================================================
2025-12-17 09:43:26 [INFO] [lib.training.pipeline:2464] Stage 5: Model Training Pipeline Completed
2025-12-17 09:43:26 [INFO] [lib.training.pipeline:2465] ================================================================================
2025-12-17 09:43:26 [INFO] [__main__:401] ================================================================================
2025-12-17 09:43:26 [INFO] [__main__:402] STAGE 5 COMPLETED SUCCESSFULLY
2025-12-17 09:43:26 [INFO] [__main__:403] ================================================================================
2025-12-17 09:43:26 [INFO] [__main__:404] Execution time: 78748.66 seconds (1312.48 minutes)
2025-12-17 09:43:26 [INFO] [__main__:406] Output directory: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-17 09:43:26 [INFO] [__main__:407] Models trained: ['xgboost_vit_transformer']
2025-12-17 09:43:26 [INFO] [__main__:408] K-fold splits: 5
2025-12-17 09:43:26 [INFO] [__main__:414] ================================================================================
2025-12-17 09:43:26 [INFO] [__main__:415] Final memory statistics:
2025-12-17 09:43:26 [INFO] [__main__:416] ================================================================================
2025-12-17 09:43:26 [INFO] [lib.utils.memory:91] Memory stats (Stage 5: after training): {'cpu_memory_mb': 12456.44921875, 'cpu_memory_gb': 12.164501190185547, 'cpu_vms_mb': 62978.59765625, 'gpu_allocated_gb': 0.009568256, 'gpu_reserved_gb': 0.025165824, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 16.903176192}
2025-12-17 09:43:26 [INFO] [__main__:419] ================================================================================
2025-12-17 09:43:26 [INFO] [__main__:420] Training complete!
2025-12-17 09:43:26 [INFO] [__main__:421] Results saved to: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-17 09:43:26 [INFO] [__main__:422] ================================================================================

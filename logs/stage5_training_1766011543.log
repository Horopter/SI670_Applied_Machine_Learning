2025-12-17 17:45:43 [INFO] [__main__:310] ================================================================================
2025-12-17 17:45:43 [INFO] [__main__:311] STAGE 5: MODEL TRAINING
2025-12-17 17:45:43 [INFO] [__main__:312] ================================================================================
2025-12-17 17:45:43 [INFO] [__main__:313] Project root: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc
2025-12-17 17:45:43 [INFO] [__main__:314] Scaled metadata: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-17 17:45:43 [INFO] [__main__:315] Features Stage 2: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage2/features_metadata.arrow
2025-12-17 17:45:43 [INFO] [__main__:316] Features Stage 4: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage4/features_scaled_metadata.arrow
2025-12-17 17:45:43 [INFO] [__main__:317] Model types: ['xgboost_vit_gru']
2025-12-17 17:45:43 [INFO] [__main__:318] K-fold splits: 5
2025-12-17 17:45:43 [INFO] [__main__:319] Number of frames: 1000
2025-12-17 17:45:43 [INFO] [__main__:320] Output directory: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-17 17:45:43 [INFO] [__main__:321] Experiment tracking: Enabled
2025-12-17 17:45:43 [INFO] [__main__:324] Delete existing: True
2025-12-17 17:45:43 [INFO] [__main__:325] Resume mode: True
2025-12-17 17:45:43 [INFO] [__main__:326] Log file: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/logs/stage5_training_1766011543.log
2025-12-17 17:45:43 [INFO] [__main__:333] ================================================================================
2025-12-17 17:45:43 [INFO] [__main__:334] Checking prerequisites...
2025-12-17 17:45:43 [INFO] [__main__:335] ================================================================================
2025-12-17 17:45:43 [INFO] [__main__:342] ✓ Scaled metadata file found: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-17 17:45:43 [INFO] [__main__:352] ✓ All model types are valid
2025-12-17 17:45:43 [INFO] [__main__:358] ================================================================================
2025-12-17 17:45:43 [INFO] [__main__:359] Initial memory statistics:
2025-12-17 17:45:43 [INFO] [__main__:360] ================================================================================
2025-12-17 17:45:43 [INFO] [lib.utils.memory:91] Memory stats (Stage 5: before training): {'cpu_memory_mb': 735.9140625, 'cpu_memory_gb': 0.7186660766601562, 'cpu_vms_mb': 10218.66015625, 'gpu_allocated_gb': 0.0, 'gpu_reserved_gb': 0.0, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 16.928342016}
2025-12-17 17:45:43 [INFO] [__main__:364] ================================================================================
2025-12-17 17:45:43 [INFO] [__main__:365] Starting Stage 5: Model Training
2025-12-17 17:45:43 [INFO] [__main__:366] ================================================================================
2025-12-17 17:45:43 [INFO] [__main__:367] Training 1 model(s) with 5-fold cross-validation
2025-12-17 17:45:43 [INFO] [__main__:368] This may take a while depending on dataset size and model complexity...
2025-12-17 17:45:43 [INFO] [__main__:369] Progress will be logged in real-time
2025-12-17 17:45:43 [INFO] [__main__:370] ================================================================================
2025-12-17 17:45:43 [INFO] [__main__:375] Calling Stage 5 training pipeline...
2025-12-17 17:45:43 [INFO] [__main__:376] This may take a while - progress will be logged in real-time
2025-12-17 17:45:43 [INFO] [lib.training.pipeline:1443] Applied global PyTorch memory optimizations at pipeline start
2025-12-17 17:45:43 [INFO] [lib.training.pipeline:1446] ================================================================================
2025-12-17 17:45:43 [INFO] [lib.training.pipeline:1447] Stage 5: Model Training Pipeline Started
2025-12-17 17:45:43 [INFO] [lib.training.pipeline:1448] ================================================================================
2025-12-17 17:45:43 [INFO] [lib.training.pipeline:1449] Model types: ['xgboost_vit_gru']
2025-12-17 17:45:43 [INFO] [lib.training.pipeline:1450] K-fold splits: 5
2025-12-17 17:45:43 [INFO] [lib.training.pipeline:1451] Frames per video: 1000
2025-12-17 17:45:43 [INFO] [lib.training.pipeline:1452] Output directory: data/stage5
2025-12-17 17:45:43 [INFO] [lib.training.pipeline:1453] Initializing pipeline...
2025-12-17 17:45:43 [INFO] [lib.training.pipeline:246] ================================================================================
2025-12-17 17:45:43 [INFO] [lib.training.pipeline:247] STAGE 5 PREREQUISITE VALIDATION
2025-12-17 17:45:43 [INFO] [lib.training.pipeline:248] ================================================================================
2025-12-17 17:45:43 [INFO] [lib.training.pipeline:250] 
[1/3] Checking Stage 3 (scaled videos) - REQUIRED for all models...
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:259] ✓ Stage 3 metadata found: 3278 scaled videos
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:260]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:262] 
[2/3] Checking Stage 2 (features) - REQUIRED for *_stage2 models...
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:270] ✓ Stage 2 metadata found: 3278 feature rows
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:271]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage2/features_metadata.arrow
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:273] 
[3/3] Checking Stage 4 (scaled features) - REQUIRED for *_stage2_stage4 models...
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:281] ✓ Stage 4 metadata found: 3277 feature rows
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:282]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage4/features_scaled_metadata.arrow
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:284] 
================================================================================
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:285] MODEL REQUIREMENTS CHECK
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:286] ================================================================================
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:305] ✓ xgboost_vit_gru: CAN RUN
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:307] 
================================================================================
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:308] VALIDATION SUMMARY
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:309] ================================================================================
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:310] Stage 3 (scaled videos): ✓ Available
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:311]   Count: 3278 videos
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:312] Stage 2 (features): ✓ Available
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:313]   Count: 3278 feature rows
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:314] Stage 4 (scaled features): ✓ Available
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:315]   Count: 3277 feature rows
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:316] 
Runnable models: 1/1
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:317]   ['xgboost_vit_gru']
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:324] ================================================================================
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:1534] 
Stage 5: Loading metadata...
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:1558] Loaded metadata: 3278 rows
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:1568] ✓ Data validation passed: 3278 rows (> 3000 required)
2025-12-17 17:45:45 [WARNING] [lib.utils.guardrails:171] Disk usage high: free=759769.57GB, used=1740070.43GB (69.6%)
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:1589] Loading Stage 2 and Stage 4 features (required for feature-based models)...
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:1599] Stage 5: Found 3278 scaled videos
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:1602] ================================================================================
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:1603] STAGE 5: VALIDATING VIDEOS (checking for corruption and empty videos)
2025-12-17 17:45:45 [INFO] [lib.training.pipeline:1604] ================================================================================
2025-12-17 17:45:45 [INFO] [lib.data.loading:156] Checking file existence for 3278 videos...
2025-12-17 17:45:51 [INFO] [lib.data.loading:166] Found 3278 existing video files (filtered out 0 missing files)
2025-12-17 17:45:51 [INFO] [lib.data.loading:170] Checking for corrupted videos (moov atom errors, etc.)...
2025-12-17 17:45:55 [INFO] [lib.data.loading:92] Loaded validation cache from /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/.video_validation_cache/validation_0192be168a40eb7e_corruptTrue_framesTrue.parquet (3278 entries)
2025-12-17 17:45:55 [INFO] [lib.data.loading:194] Cache hit: 3278 videos, Cache miss: 0 videos
2025-12-17 17:45:56 [WARNING] [lib.data.loading:306] Filtered out 1 corrupted videos and 0 empty videos. Keeping 3277 valid videos.
2025-12-17 17:45:56 [WARNING] [lib.data.loading:311] Sample of invalid videos:
2025-12-17 17:45:56 [WARNING] [lib.data.loading:313]   data/scaled_videos/FX5aeuJFQ64_aug1_scaled_aug1.mp4: Corrupted video: moov atom not found
2025-12-17 17:45:56 [INFO] [lib.data.loading:323] Found /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/skip_frame_check.txt - skipping frame check as requested.
2025-12-17 17:45:56 [WARNING] [lib.data.loading:387] Filtered out 1 invalid videos (corrupted). Keeping 3277 valid videos.
2025-12-17 17:45:56 [INFO] [lib.training.pipeline:1613] ✓ Video validation complete: 3277 valid videos ready for training
2025-12-17 17:45:56 [INFO] [lib.training.pipeline:1614] ================================================================================
2025-12-17 17:45:56 [INFO] [lib.training.pipeline:1700] Frame caching enabled (default): cache_dir=data/.frame_cache. This will cache processed frames to disk to speed up training. First epoch will be slower (building cache), subsequent epochs will be faster. To disable, set FVC_USE_FRAME_CACHE=0
2025-12-17 17:45:56 [INFO] [lib.training.pipeline:1773] Overriding num_frames to 400 for xgboost_vit_gru. Original num_frames was 1000.
2025-12-17 17:45:56 [INFO] [lib.training.pipeline:1801] Stage 5: Deleting existing model results (clean mode)...
2025-12-17 17:45:57 [INFO] [lib.training.pipeline:1809] Deleted existing results for xgboost_vit_gru
2025-12-17 17:45:57 [INFO] [lib.training.pipeline:1812] Stage 5: Deleted 1 existing model directories
2025-12-17 17:45:57 [INFO] [lib.training.pipeline:1816] 
================================================================================
2025-12-17 17:45:57 [INFO] [lib.training.pipeline:1817] Stage 5: Training model: xgboost_vit_gru
2025-12-17 17:45:57 [INFO] [lib.training.pipeline:1818] ================================================================================
2025-12-17 17:45:57 [INFO] [lib.training.pipeline:1836] Overriding model_config num_frames to 400 for xgboost_vit_gru (XGBoost pretrained model with enhanced feature extraction) to improve feature quality.
2025-12-17 17:45:57 [INFO] [lib.training.pipeline:1854] Grid search: 1 hyperparameter combinations to try
2025-12-17 17:45:57 [INFO] [lib.training.pipeline:1862] ================================================================================
2025-12-17 17:45:57 [INFO] [lib.training.pipeline:1863] HYPERPARAMETER SEARCH: Using 10.0% stratified sample for efficiency
2025-12-17 17:45:57 [INFO] [lib.training.pipeline:1864] ================================================================================
2025-12-17 17:45:57 [INFO] [lib.training.pipeline:1873] Hyperparameter search sample: 327 rows (10.0% of 3277 total)
2025-12-17 17:45:57 [INFO] [lib.training.pipeline:1874] To change sample size, set FVC_GRID_SEARCH_SAMPLE_SIZE environment variable (current: 0.1)
2025-12-17 17:45:57 [INFO] [lib.training.pipeline:1886] Using 5-fold stratified cross-validation on 10.0% sample for hyperparameter search
2025-12-17 17:45:57 [INFO] [lib.training.pipeline:1897] 
================================================================================
2025-12-17 17:45:57 [INFO] [lib.training.pipeline:1898] Grid Search: Hyperparameter combination 1/1
2025-12-17 17:45:57 [INFO] [lib.training.pipeline:1899] Parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8}
2025-12-17 17:45:57 [INFO] [lib.training.pipeline:1900] ================================================================================
2025-12-17 17:45:57 [INFO] [lib.training.pipeline:1918] 
Hyperparameter Search - xgboost_vit_gru - Fold 1/5 (10.0% sample)
2025-12-17 17:45:57 [INFO] [lib.training.pipeline:448] Training XGBoost model xgboost_vit_gru on fold 1...
2025-12-17 17:45:57 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost on features from vit_gru...
2025-12-17 17:45:57 [INFO] [lib.training._xgboost_pretrained:705] Processing 261 videos...
2025-12-17 17:45:57 [INFO] [lib.training._xgboost_pretrained:590] Loading pretrained model: vit_gru (num_frames=400)
2025-12-17 17:46:07 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-17 17:46:08 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-17 17:46:08 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-17 17:46:11 [INFO] [lib.training._xgboost_pretrained:605] Loaded vit_gru model to GPU, cleared cache
2025-12-17 17:46:11 [INFO] [lib.training._xgboost_pretrained:622] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-17 17:46:12 [INFO] [lib.training._xgboost_pretrained:672] Extracting features using vit_gru (num_frames=400)...
2025-12-17 17:46:12 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-17 18:04:14 [INFO] [lib.training._xgboost_pretrained:478] Extracted features shape: (261, 3072)
2025-12-17 18:04:15 [INFO] [lib.training._xgboost_pretrained:690] Cleared vit_gru model from GPU after feature extraction
2025-12-17 18:04:15 [INFO] [lib.training._xgboost_pretrained:728] Removing collinear features...
2025-12-17 18:04:15 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-17 18:04:17 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-17 18:04:17 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-17 18:04:17 [INFO] [lib.training._xgboost_pretrained:735] Using 3072 features after collinearity removal
2025-12-17 18:04:17 [INFO] [lib.training._xgboost_pretrained:751] Class distribution: Class 0=128, Class 1=133, scale_pos_weight=0.962
2025-12-17 18:04:17 [INFO] [lib.training._xgboost_pretrained:769] Training XGBoost: 208 train samples, 53 validation samples for early stopping
2025-12-17 18:04:17 [INFO] [lib.training._xgboost_pretrained:772] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-17 18:04:26 [INFO] [lib.training._xgboost_pretrained:838] Early stopping: Best iteration = 200 (out of 200)
2025-12-17 18:04:26 [INFO] [lib.training._xgboost_pretrained:840] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-17 18:04:26 [INFO] [lib.training._xgboost_pretrained:590] Loading pretrained model: vit_gru (num_frames=400)
2025-12-17 18:04:27 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-17 18:04:27 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-17 18:04:27 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-17 18:04:28 [INFO] [lib.training._xgboost_pretrained:605] Loaded vit_gru model to GPU, cleared cache
2025-12-17 18:04:28 [INFO] [lib.training._xgboost_pretrained:622] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-17 18:04:28 [INFO] [lib.training._xgboost_pretrained:672] Extracting features using vit_gru (num_frames=400)...
2025-12-17 18:04:28 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-17 18:09:17 [INFO] [lib.training._xgboost_pretrained:478] Extracted features shape: (66, 3072)
2025-12-17 18:09:17 [INFO] [lib.training._xgboost_pretrained:690] Cleared vit_gru model from GPU after feature extraction
2025-12-17 18:09:17 [INFO] [lib.training.pipeline:500] Fold 1 - Val Loss: 0.4664, Val Acc: 0.7727, Val F1: 0.7692, Val Precision: 0.8065, Val Recall: 0.7353
2025-12-17 18:09:17 [INFO] [lib.training.pipeline:505]   Class 0 - Precision: 0.7429, Recall: 0.8125, F1: 0.7761
2025-12-17 18:09:17 [INFO] [lib.training.pipeline:509]   Class 1 - Precision: 0.8065, Recall: 0.7353, F1: 0.7692
2025-12-17 18:09:17 [INFO] [lib.training._xgboost_pretrained:908] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_1
2025-12-17 18:09:17 [INFO] [lib.training.pipeline:516] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_1
2025-12-17 18:09:24 [INFO] [lib.training.visualization:480] Generated fold 1 plots: ROC/PR curves and confusion matrix
2025-12-17 18:09:24 [INFO] [lib.training.pipeline:1918] 
Hyperparameter Search - xgboost_vit_gru - Fold 2/5 (10.0% sample)
2025-12-17 18:09:24 [INFO] [lib.training.pipeline:448] Training XGBoost model xgboost_vit_gru on fold 2...
2025-12-17 18:09:24 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost on features from vit_gru...
2025-12-17 18:09:24 [INFO] [lib.training._xgboost_pretrained:705] Processing 261 videos...
2025-12-17 18:09:25 [INFO] [lib.training._xgboost_pretrained:590] Loading pretrained model: vit_gru (num_frames=400)
2025-12-17 18:09:26 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-17 18:09:26 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-17 18:09:26 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-17 18:09:26 [INFO] [lib.training._xgboost_pretrained:605] Loaded vit_gru model to GPU, cleared cache
2025-12-17 18:09:26 [INFO] [lib.training._xgboost_pretrained:622] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-17 18:09:26 [INFO] [lib.training._xgboost_pretrained:672] Extracting features using vit_gru (num_frames=400)...
2025-12-17 18:09:26 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-17 18:28:00 [INFO] [lib.training._xgboost_pretrained:478] Extracted features shape: (261, 3072)
2025-12-17 18:28:00 [INFO] [lib.training._xgboost_pretrained:690] Cleared vit_gru model from GPU after feature extraction
2025-12-17 18:28:01 [INFO] [lib.training._xgboost_pretrained:728] Removing collinear features...
2025-12-17 18:28:01 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-17 18:28:02 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-17 18:28:02 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-17 18:28:02 [INFO] [lib.training._xgboost_pretrained:735] Using 3072 features after collinearity removal
2025-12-17 18:28:02 [INFO] [lib.training._xgboost_pretrained:751] Class distribution: Class 0=128, Class 1=133, scale_pos_weight=0.962
2025-12-17 18:28:02 [INFO] [lib.training._xgboost_pretrained:769] Training XGBoost: 208 train samples, 53 validation samples for early stopping
2025-12-17 18:28:02 [INFO] [lib.training._xgboost_pretrained:772] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-17 18:28:10 [INFO] [lib.training._xgboost_pretrained:838] Early stopping: Best iteration = 172 (out of 200)
2025-12-17 18:28:10 [INFO] [lib.training._xgboost_pretrained:840] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-17 18:28:10 [INFO] [lib.training._xgboost_pretrained:590] Loading pretrained model: vit_gru (num_frames=400)
2025-12-17 18:28:11 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-17 18:28:11 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-17 18:28:11 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-17 18:28:12 [INFO] [lib.training._xgboost_pretrained:605] Loaded vit_gru model to GPU, cleared cache
2025-12-17 18:28:12 [INFO] [lib.training._xgboost_pretrained:622] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-17 18:28:12 [INFO] [lib.training._xgboost_pretrained:672] Extracting features using vit_gru (num_frames=400)...
2025-12-17 18:28:12 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-17 18:33:12 [INFO] [lib.training._xgboost_pretrained:478] Extracted features shape: (66, 3072)
2025-12-17 18:33:13 [INFO] [lib.training._xgboost_pretrained:690] Cleared vit_gru model from GPU after feature extraction
2025-12-17 18:33:13 [INFO] [lib.training.pipeline:500] Fold 2 - Val Loss: 0.3902, Val Acc: 0.7879, Val F1: 0.7879, Val Precision: 0.8125, Val Recall: 0.7647
2025-12-17 18:33:13 [INFO] [lib.training.pipeline:505]   Class 0 - Precision: 0.7647, Recall: 0.8125, F1: 0.7879
2025-12-17 18:33:13 [INFO] [lib.training.pipeline:509]   Class 1 - Precision: 0.8125, Recall: 0.7647, F1: 0.7879
2025-12-17 18:33:13 [INFO] [lib.training._xgboost_pretrained:908] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_2
2025-12-17 18:33:13 [INFO] [lib.training.pipeline:516] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_2
2025-12-17 18:33:14 [INFO] [lib.training.visualization:480] Generated fold 2 plots: ROC/PR curves and confusion matrix
2025-12-17 18:33:14 [INFO] [lib.training.pipeline:1918] 
Hyperparameter Search - xgboost_vit_gru - Fold 3/5 (10.0% sample)
2025-12-17 18:33:14 [INFO] [lib.training.pipeline:448] Training XGBoost model xgboost_vit_gru on fold 3...
2025-12-17 18:33:14 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost on features from vit_gru...
2025-12-17 18:33:14 [INFO] [lib.training._xgboost_pretrained:705] Processing 262 videos...
2025-12-17 18:33:14 [INFO] [lib.training._xgboost_pretrained:590] Loading pretrained model: vit_gru (num_frames=400)
2025-12-17 18:33:15 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-17 18:33:16 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-17 18:33:16 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-17 18:33:16 [INFO] [lib.training._xgboost_pretrained:605] Loaded vit_gru model to GPU, cleared cache
2025-12-17 18:33:16 [INFO] [lib.training._xgboost_pretrained:622] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-17 18:33:16 [INFO] [lib.training._xgboost_pretrained:672] Extracting features using vit_gru (num_frames=400)...
2025-12-17 18:33:16 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-17 18:51:37 [INFO] [lib.training._xgboost_pretrained:478] Extracted features shape: (262, 3072)
2025-12-17 18:51:38 [INFO] [lib.training._xgboost_pretrained:690] Cleared vit_gru model from GPU after feature extraction
2025-12-17 18:51:38 [INFO] [lib.training._xgboost_pretrained:728] Removing collinear features...
2025-12-17 18:51:38 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-17 18:51:39 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-17 18:51:39 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-17 18:51:39 [INFO] [lib.training._xgboost_pretrained:735] Using 3072 features after collinearity removal
2025-12-17 18:51:39 [INFO] [lib.training._xgboost_pretrained:751] Class distribution: Class 0=128, Class 1=134, scale_pos_weight=0.955
2025-12-17 18:51:39 [INFO] [lib.training._xgboost_pretrained:769] Training XGBoost: 209 train samples, 53 validation samples for early stopping
2025-12-17 18:51:39 [INFO] [lib.training._xgboost_pretrained:772] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-17 18:51:43 [INFO] [lib.training._xgboost_pretrained:838] Early stopping: Best iteration = 32 (out of 200)
2025-12-17 18:51:43 [INFO] [lib.training._xgboost_pretrained:840] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-17 18:51:43 [INFO] [lib.training._xgboost_pretrained:590] Loading pretrained model: vit_gru (num_frames=400)
2025-12-17 18:51:44 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-17 18:51:44 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-17 18:51:44 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-17 18:51:45 [INFO] [lib.training._xgboost_pretrained:605] Loaded vit_gru model to GPU, cleared cache
2025-12-17 18:51:45 [INFO] [lib.training._xgboost_pretrained:622] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-17 18:51:45 [INFO] [lib.training._xgboost_pretrained:672] Extracting features using vit_gru (num_frames=400)...
2025-12-17 18:51:45 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-17 18:56:24 [INFO] [lib.training._xgboost_pretrained:478] Extracted features shape: (65, 3072)
2025-12-17 18:56:25 [INFO] [lib.training._xgboost_pretrained:690] Cleared vit_gru model from GPU after feature extraction
2025-12-17 18:56:25 [INFO] [lib.training.pipeline:500] Fold 3 - Val Loss: 0.5288, Val Acc: 0.7385, Val F1: 0.7213, Val Precision: 0.7857, Val Recall: 0.6667
2025-12-17 18:56:25 [INFO] [lib.training.pipeline:505]   Class 0 - Precision: 0.7027, Recall: 0.8125, F1: 0.7536
2025-12-17 18:56:25 [INFO] [lib.training.pipeline:509]   Class 1 - Precision: 0.7857, Recall: 0.6667, F1: 0.7213
2025-12-17 18:56:25 [INFO] [lib.training._xgboost_pretrained:908] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_3
2025-12-17 18:56:25 [INFO] [lib.training.pipeline:516] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_3
2025-12-17 18:56:26 [INFO] [lib.training.visualization:480] Generated fold 3 plots: ROC/PR curves and confusion matrix
2025-12-17 18:56:26 [INFO] [lib.training.pipeline:1918] 
Hyperparameter Search - xgboost_vit_gru - Fold 4/5 (10.0% sample)
2025-12-17 18:56:26 [INFO] [lib.training.pipeline:448] Training XGBoost model xgboost_vit_gru on fold 4...
2025-12-17 18:56:26 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost on features from vit_gru...
2025-12-17 18:56:26 [INFO] [lib.training._xgboost_pretrained:705] Processing 262 videos...
2025-12-17 18:56:26 [INFO] [lib.training._xgboost_pretrained:590] Loading pretrained model: vit_gru (num_frames=400)
2025-12-17 18:56:27 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-17 18:56:28 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-17 18:56:28 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-17 18:56:28 [INFO] [lib.training._xgboost_pretrained:605] Loaded vit_gru model to GPU, cleared cache
2025-12-17 18:56:28 [INFO] [lib.training._xgboost_pretrained:622] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-17 18:56:29 [INFO] [lib.training._xgboost_pretrained:672] Extracting features using vit_gru (num_frames=400)...
2025-12-17 18:56:29 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-17 19:14:07 [INFO] [lib.training._xgboost_pretrained:478] Extracted features shape: (262, 3072)
2025-12-17 19:14:08 [INFO] [lib.training._xgboost_pretrained:690] Cleared vit_gru model from GPU after feature extraction
2025-12-17 19:14:08 [INFO] [lib.training._xgboost_pretrained:728] Removing collinear features...
2025-12-17 19:14:08 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-17 19:14:09 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-17 19:14:09 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-17 19:14:09 [INFO] [lib.training._xgboost_pretrained:735] Using 3072 features after collinearity removal
2025-12-17 19:14:09 [INFO] [lib.training._xgboost_pretrained:751] Class distribution: Class 0=128, Class 1=134, scale_pos_weight=0.955
2025-12-17 19:14:09 [INFO] [lib.training._xgboost_pretrained:769] Training XGBoost: 209 train samples, 53 validation samples for early stopping
2025-12-17 19:14:09 [INFO] [lib.training._xgboost_pretrained:772] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-17 19:14:13 [INFO] [lib.training._xgboost_pretrained:838] Early stopping: Best iteration = 51 (out of 200)
2025-12-17 19:14:13 [INFO] [lib.training._xgboost_pretrained:840] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-17 19:14:14 [INFO] [lib.training._xgboost_pretrained:590] Loading pretrained model: vit_gru (num_frames=400)
2025-12-17 19:14:15 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-17 19:14:15 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-17 19:14:15 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-17 19:14:16 [INFO] [lib.training._xgboost_pretrained:605] Loaded vit_gru model to GPU, cleared cache
2025-12-17 19:14:16 [INFO] [lib.training._xgboost_pretrained:622] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-17 19:14:16 [INFO] [lib.training._xgboost_pretrained:672] Extracting features using vit_gru (num_frames=400)...
2025-12-17 19:14:16 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-17 19:18:32 [INFO] [lib.training._xgboost_pretrained:478] Extracted features shape: (65, 3072)
2025-12-17 19:18:33 [INFO] [lib.training._xgboost_pretrained:690] Cleared vit_gru model from GPU after feature extraction
2025-12-17 19:18:33 [INFO] [lib.training.pipeline:500] Fold 4 - Val Loss: 0.4936, Val Acc: 0.7846, Val F1: 0.7941, Val Precision: 0.7714, Val Recall: 0.8182
2025-12-17 19:18:33 [INFO] [lib.training.pipeline:505]   Class 0 - Precision: 0.8000, Recall: 0.7500, F1: 0.7742
2025-12-17 19:18:33 [INFO] [lib.training.pipeline:509]   Class 1 - Precision: 0.7714, Recall: 0.8182, F1: 0.7941
2025-12-17 19:18:33 [INFO] [lib.training._xgboost_pretrained:908] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_4
2025-12-17 19:18:33 [INFO] [lib.training.pipeline:516] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_4
2025-12-17 19:18:34 [INFO] [lib.training.visualization:480] Generated fold 4 plots: ROC/PR curves and confusion matrix
2025-12-17 19:18:34 [INFO] [lib.training.pipeline:1918] 
Hyperparameter Search - xgboost_vit_gru - Fold 5/5 (10.0% sample)
2025-12-17 19:18:34 [INFO] [lib.training.pipeline:448] Training XGBoost model xgboost_vit_gru on fold 5...
2025-12-17 19:18:34 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost on features from vit_gru...
2025-12-17 19:18:34 [INFO] [lib.training._xgboost_pretrained:705] Processing 262 videos...
2025-12-17 19:18:34 [INFO] [lib.training._xgboost_pretrained:590] Loading pretrained model: vit_gru (num_frames=400)
2025-12-17 19:18:35 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-17 19:18:36 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-17 19:18:36 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-17 19:18:36 [INFO] [lib.training._xgboost_pretrained:605] Loaded vit_gru model to GPU, cleared cache
2025-12-17 19:18:36 [INFO] [lib.training._xgboost_pretrained:622] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-17 19:18:36 [INFO] [lib.training._xgboost_pretrained:672] Extracting features using vit_gru (num_frames=400)...
2025-12-17 19:18:36 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-17 19:36:23 [INFO] [lib.training._xgboost_pretrained:478] Extracted features shape: (262, 3072)
2025-12-17 19:36:23 [INFO] [lib.training._xgboost_pretrained:690] Cleared vit_gru model from GPU after feature extraction
2025-12-17 19:36:23 [INFO] [lib.training._xgboost_pretrained:728] Removing collinear features...
2025-12-17 19:36:23 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-17 19:36:24 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-17 19:36:24 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-17 19:36:24 [INFO] [lib.training._xgboost_pretrained:735] Using 3072 features after collinearity removal
2025-12-17 19:36:24 [INFO] [lib.training._xgboost_pretrained:751] Class distribution: Class 0=128, Class 1=134, scale_pos_weight=0.955
2025-12-17 19:36:24 [INFO] [lib.training._xgboost_pretrained:769] Training XGBoost: 209 train samples, 53 validation samples for early stopping
2025-12-17 19:36:24 [INFO] [lib.training._xgboost_pretrained:772] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-17 19:36:31 [INFO] [lib.training._xgboost_pretrained:838] Early stopping: Best iteration = 111 (out of 200)
2025-12-17 19:36:31 [INFO] [lib.training._xgboost_pretrained:840] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-17 19:36:32 [INFO] [lib.training._xgboost_pretrained:590] Loading pretrained model: vit_gru (num_frames=400)
2025-12-17 19:36:33 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-17 19:36:33 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-17 19:36:33 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-17 19:36:34 [INFO] [lib.training._xgboost_pretrained:605] Loaded vit_gru model to GPU, cleared cache
2025-12-17 19:36:34 [INFO] [lib.training._xgboost_pretrained:622] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-17 19:36:34 [INFO] [lib.training._xgboost_pretrained:672] Extracting features using vit_gru (num_frames=400)...
2025-12-17 19:36:34 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-17 19:40:38 [INFO] [lib.training._xgboost_pretrained:478] Extracted features shape: (65, 3072)
2025-12-17 19:40:39 [INFO] [lib.training._xgboost_pretrained:690] Cleared vit_gru model from GPU after feature extraction
2025-12-17 19:40:39 [INFO] [lib.training.pipeline:500] Fold 5 - Val Loss: 0.4740, Val Acc: 0.7692, Val F1: 0.7692, Val Precision: 0.7812, Val Recall: 0.7576
2025-12-17 19:40:39 [INFO] [lib.training.pipeline:505]   Class 0 - Precision: 0.7576, Recall: 0.7812, F1: 0.7692
2025-12-17 19:40:39 [INFO] [lib.training.pipeline:509]   Class 1 - Precision: 0.7812, Recall: 0.7576, F1: 0.7692
2025-12-17 19:40:39 [INFO] [lib.training._xgboost_pretrained:908] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_5
2025-12-17 19:40:39 [INFO] [lib.training.pipeline:516] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_5
2025-12-17 19:40:40 [INFO] [lib.training.visualization:480] Generated fold 5 plots: ROC/PR curves and confusion matrix
2025-12-17 19:40:40 [INFO] [lib.training.pipeline:2079] Parameter combination 1 - Mean F1: 0.7684, Mean Acc: 0.7706
2025-12-17 19:40:40 [INFO] [lib.training.pipeline:2091] Using single parameter combination: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8}
2025-12-17 19:40:40 [INFO] [lib.training.pipeline:2094] ================================================================================
2025-12-17 19:40:40 [INFO] [lib.training.pipeline:2095] FINAL TRAINING: Using full dataset with best hyperparameters
2025-12-17 19:40:40 [INFO] [lib.training.pipeline:2096] ================================================================================
2025-12-17 19:40:40 [INFO] [lib.training.pipeline:2109] Final training: Using 5-fold stratified cross-validation on full dataset (3277 rows)
2025-12-17 19:40:40 [INFO] [lib.training.pipeline:2117] Final training using best hyperparameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8}
2025-12-17 19:40:40 [INFO] [lib.training.pipeline:2123] 
Final Training - xgboost_vit_gru - Fold 1/5 (full dataset)
2025-12-17 19:40:40 [INFO] [lib.training.pipeline:2131] Deleted existing final training fold 1 directory (clean mode)
2025-12-17 19:40:40 [INFO] [lib.training.pipeline:448] Training XGBoost model xgboost_vit_gru on fold 1...
2025-12-17 19:40:40 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost on features from vit_gru...
2025-12-17 19:40:40 [INFO] [lib.training._xgboost_pretrained:705] Processing 2621 videos...
2025-12-17 19:40:41 [INFO] [lib.training._xgboost_pretrained:590] Loading pretrained model: vit_gru (num_frames=400)
2025-12-17 19:40:42 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-17 19:40:42 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-17 19:40:42 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-17 19:40:42 [INFO] [lib.training._xgboost_pretrained:605] Loaded vit_gru model to GPU, cleared cache
2025-12-17 19:40:42 [INFO] [lib.training._xgboost_pretrained:622] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-17 19:40:42 [INFO] [lib.training._xgboost_pretrained:672] Extracting features using vit_gru (num_frames=400)...
2025-12-17 19:40:43 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-17 23:08:22 [INFO] [lib.training._xgboost_pretrained:478] Extracted features shape: (2621, 3072)
2025-12-17 23:08:22 [INFO] [lib.training._xgboost_pretrained:690] Cleared vit_gru model from GPU after feature extraction
2025-12-17 23:08:22 [INFO] [lib.training._xgboost_pretrained:728] Removing collinear features...
2025-12-17 23:08:23 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-17 23:08:24 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-17 23:08:24 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-17 23:08:24 [INFO] [lib.training._xgboost_pretrained:735] Using 3072 features after collinearity removal
2025-12-17 23:08:24 [INFO] [lib.training._xgboost_pretrained:751] Class distribution: Class 0=1284, Class 1=1337, scale_pos_weight=0.960
2025-12-17 23:08:24 [INFO] [lib.training._xgboost_pretrained:769] Training XGBoost: 2096 train samples, 525 validation samples for early stopping
2025-12-17 23:08:24 [INFO] [lib.training._xgboost_pretrained:772] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-17 23:09:19 [INFO] [lib.training._xgboost_pretrained:838] Early stopping: Best iteration = 200 (out of 200)
2025-12-17 23:09:19 [INFO] [lib.training._xgboost_pretrained:840] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-17 23:09:20 [INFO] [lib.training._xgboost_pretrained:590] Loading pretrained model: vit_gru (num_frames=400)
2025-12-17 23:09:21 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-17 23:09:22 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-17 23:09:22 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-17 23:09:22 [INFO] [lib.training._xgboost_pretrained:605] Loaded vit_gru model to GPU, cleared cache
2025-12-17 23:09:22 [INFO] [lib.training._xgboost_pretrained:622] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-17 23:09:22 [INFO] [lib.training._xgboost_pretrained:672] Extracting features using vit_gru (num_frames=400)...
2025-12-17 23:09:23 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-17 23:58:07 [INFO] [lib.training._xgboost_pretrained:478] Extracted features shape: (656, 3072)
2025-12-17 23:58:07 [INFO] [lib.training._xgboost_pretrained:690] Cleared vit_gru model from GPU after feature extraction
2025-12-17 23:58:08 [INFO] [lib.training.pipeline:500] Fold 1 - Val Loss: 0.0490, Val Acc: 0.9954, Val F1: 0.9955, Val Precision: 0.9970, Val Recall: 0.9940
2025-12-17 23:58:08 [INFO] [lib.training._xgboost_pretrained:908] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_1
2025-12-17 23:58:08 [INFO] [lib.training.pipeline:516] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_1
2025-12-17 23:58:10 [INFO] [lib.training.visualization:480] Generated fold 1 plots: ROC/PR curves and confusion matrix
2025-12-17 23:58:10 [INFO] [lib.training.pipeline:2123] 
Final Training - xgboost_vit_gru - Fold 2/5 (full dataset)
2025-12-17 23:58:10 [INFO] [lib.training.pipeline:2131] Deleted existing final training fold 2 directory (clean mode)
2025-12-17 23:58:10 [INFO] [lib.training.pipeline:448] Training XGBoost model xgboost_vit_gru on fold 2...
2025-12-17 23:58:10 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost on features from vit_gru...
2025-12-17 23:58:10 [INFO] [lib.training._xgboost_pretrained:705] Processing 2621 videos...
2025-12-17 23:58:10 [INFO] [lib.training._xgboost_pretrained:590] Loading pretrained model: vit_gru (num_frames=400)
2025-12-17 23:58:11 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-17 23:58:11 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-17 23:58:12 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-17 23:58:12 [INFO] [lib.training._xgboost_pretrained:605] Loaded vit_gru model to GPU, cleared cache
2025-12-17 23:58:12 [INFO] [lib.training._xgboost_pretrained:622] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-17 23:58:12 [INFO] [lib.training._xgboost_pretrained:672] Extracting features using vit_gru (num_frames=400)...
2025-12-17 23:58:13 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-18 03:09:27 [INFO] [lib.training._xgboost_pretrained:478] Extracted features shape: (2621, 3072)
2025-12-18 03:09:28 [INFO] [lib.training._xgboost_pretrained:690] Cleared vit_gru model from GPU after feature extraction
2025-12-18 03:09:28 [INFO] [lib.training._xgboost_pretrained:728] Removing collinear features...
2025-12-18 03:09:28 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-18 03:09:30 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-18 03:09:30 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-18 03:09:30 [INFO] [lib.training._xgboost_pretrained:735] Using 3072 features after collinearity removal
2025-12-18 03:09:30 [INFO] [lib.training._xgboost_pretrained:751] Class distribution: Class 0=1284, Class 1=1337, scale_pos_weight=0.960
2025-12-18 03:09:30 [INFO] [lib.training._xgboost_pretrained:769] Training XGBoost: 2096 train samples, 525 validation samples for early stopping
2025-12-18 03:09:30 [INFO] [lib.training._xgboost_pretrained:772] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-18 03:10:24 [INFO] [lib.training._xgboost_pretrained:838] Early stopping: Best iteration = 200 (out of 200)
2025-12-18 03:10:24 [INFO] [lib.training._xgboost_pretrained:840] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-18 03:10:25 [INFO] [lib.training._xgboost_pretrained:590] Loading pretrained model: vit_gru (num_frames=400)
2025-12-18 03:10:26 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-18 03:10:26 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-18 03:10:26 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-18 03:10:27 [INFO] [lib.training._xgboost_pretrained:605] Loaded vit_gru model to GPU, cleared cache
2025-12-18 03:10:27 [INFO] [lib.training._xgboost_pretrained:622] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-18 03:10:27 [INFO] [lib.training._xgboost_pretrained:672] Extracting features using vit_gru (num_frames=400)...
2025-12-18 03:10:27 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-18 03:55:44 [INFO] [lib.training._xgboost_pretrained:478] Extracted features shape: (656, 3072)
2025-12-18 03:55:44 [INFO] [lib.training._xgboost_pretrained:690] Cleared vit_gru model from GPU after feature extraction
2025-12-18 03:55:44 [INFO] [lib.training.pipeline:500] Fold 2 - Val Loss: 0.0429, Val Acc: 0.9970, Val F1: 0.9970, Val Precision: 0.9970, Val Recall: 0.9970
2025-12-18 03:55:44 [INFO] [lib.training._xgboost_pretrained:908] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_2
2025-12-18 03:55:44 [INFO] [lib.training.pipeline:516] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_2
2025-12-18 03:55:46 [INFO] [lib.training.visualization:480] Generated fold 2 plots: ROC/PR curves and confusion matrix
2025-12-18 03:55:46 [INFO] [lib.training.pipeline:2123] 
Final Training - xgboost_vit_gru - Fold 3/5 (full dataset)
2025-12-18 03:55:46 [INFO] [lib.training.pipeline:2131] Deleted existing final training fold 3 directory (clean mode)
2025-12-18 03:55:46 [INFO] [lib.training.pipeline:448] Training XGBoost model xgboost_vit_gru on fold 3...
2025-12-18 03:55:46 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost on features from vit_gru...
2025-12-18 03:55:46 [INFO] [lib.training._xgboost_pretrained:705] Processing 2622 videos...
2025-12-18 03:55:46 [INFO] [lib.training._xgboost_pretrained:590] Loading pretrained model: vit_gru (num_frames=400)
2025-12-18 03:55:47 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-18 03:55:47 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-18 03:55:47 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-18 03:55:48 [INFO] [lib.training._xgboost_pretrained:605] Loaded vit_gru model to GPU, cleared cache
2025-12-18 03:55:48 [INFO] [lib.training._xgboost_pretrained:622] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-18 03:55:48 [INFO] [lib.training._xgboost_pretrained:672] Extracting features using vit_gru (num_frames=400)...
2025-12-18 03:55:48 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-18 07:00:10 [INFO] [lib.training._xgboost_pretrained:478] Extracted features shape: (2622, 3072)
2025-12-18 07:00:10 [INFO] [lib.training._xgboost_pretrained:690] Cleared vit_gru model from GPU after feature extraction
2025-12-18 07:00:11 [INFO] [lib.training._xgboost_pretrained:728] Removing collinear features...
2025-12-18 07:00:11 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-18 07:00:12 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-18 07:00:12 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-18 07:00:12 [INFO] [lib.training._xgboost_pretrained:735] Using 3072 features after collinearity removal
2025-12-18 07:00:12 [INFO] [lib.training._xgboost_pretrained:751] Class distribution: Class 0=1284, Class 1=1338, scale_pos_weight=0.960
2025-12-18 07:00:12 [INFO] [lib.training._xgboost_pretrained:769] Training XGBoost: 2097 train samples, 525 validation samples for early stopping
2025-12-18 07:00:12 [INFO] [lib.training._xgboost_pretrained:772] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-18 07:01:07 [INFO] [lib.training._xgboost_pretrained:838] Early stopping: Best iteration = 200 (out of 200)
2025-12-18 07:01:07 [INFO] [lib.training._xgboost_pretrained:840] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-18 07:01:08 [INFO] [lib.training._xgboost_pretrained:590] Loading pretrained model: vit_gru (num_frames=400)
2025-12-18 07:01:09 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-18 07:01:09 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-18 07:01:09 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-18 07:01:10 [INFO] [lib.training._xgboost_pretrained:605] Loaded vit_gru model to GPU, cleared cache
2025-12-18 07:01:10 [INFO] [lib.training._xgboost_pretrained:622] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-18 07:01:10 [INFO] [lib.training._xgboost_pretrained:672] Extracting features using vit_gru (num_frames=400)...
2025-12-18 07:01:10 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-18 07:46:10 [INFO] [lib.training._xgboost_pretrained:478] Extracted features shape: (655, 3072)
2025-12-18 07:46:11 [INFO] [lib.training._xgboost_pretrained:690] Cleared vit_gru model from GPU after feature extraction
2025-12-18 07:46:11 [INFO] [lib.training.pipeline:500] Fold 3 - Val Loss: 0.0505, Val Acc: 0.9924, Val F1: 0.9925, Val Precision: 0.9940, Val Recall: 0.9910
2025-12-18 07:46:11 [INFO] [lib.training._xgboost_pretrained:908] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_3
2025-12-18 07:46:11 [INFO] [lib.training.pipeline:516] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_3
2025-12-18 07:46:12 [INFO] [lib.training.visualization:480] Generated fold 3 plots: ROC/PR curves and confusion matrix
2025-12-18 07:46:13 [INFO] [lib.training.pipeline:2123] 
Final Training - xgboost_vit_gru - Fold 4/5 (full dataset)
2025-12-18 07:46:13 [INFO] [lib.training.pipeline:2131] Deleted existing final training fold 4 directory (clean mode)
2025-12-18 07:46:13 [INFO] [lib.training.pipeline:448] Training XGBoost model xgboost_vit_gru on fold 4...
2025-12-18 07:46:13 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost on features from vit_gru...
2025-12-18 07:46:13 [INFO] [lib.training._xgboost_pretrained:705] Processing 2622 videos...
2025-12-18 07:46:13 [INFO] [lib.training._xgboost_pretrained:590] Loading pretrained model: vit_gru (num_frames=400)
2025-12-18 07:46:14 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-18 07:46:14 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-18 07:46:14 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-18 07:46:15 [INFO] [lib.training._xgboost_pretrained:605] Loaded vit_gru model to GPU, cleared cache
2025-12-18 07:46:15 [INFO] [lib.training._xgboost_pretrained:622] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-18 07:46:15 [INFO] [lib.training._xgboost_pretrained:672] Extracting features using vit_gru (num_frames=400)...
2025-12-18 07:46:15 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-18 10:44:58 [INFO] [lib.training._xgboost_pretrained:478] Extracted features shape: (2622, 3072)
2025-12-18 10:44:58 [INFO] [lib.training._xgboost_pretrained:690] Cleared vit_gru model from GPU after feature extraction
2025-12-18 10:44:58 [INFO] [lib.training._xgboost_pretrained:728] Removing collinear features...
2025-12-18 10:44:58 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-18 10:45:00 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-18 10:45:00 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-18 10:45:00 [INFO] [lib.training._xgboost_pretrained:735] Using 3072 features after collinearity removal
2025-12-18 10:45:00 [INFO] [lib.training._xgboost_pretrained:751] Class distribution: Class 0=1284, Class 1=1338, scale_pos_weight=0.960
2025-12-18 10:45:00 [INFO] [lib.training._xgboost_pretrained:769] Training XGBoost: 2097 train samples, 525 validation samples for early stopping
2025-12-18 10:45:00 [INFO] [lib.training._xgboost_pretrained:772] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-18 10:45:55 [INFO] [lib.training._xgboost_pretrained:838] Early stopping: Best iteration = 200 (out of 200)
2025-12-18 10:45:55 [INFO] [lib.training._xgboost_pretrained:840] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-18 10:45:55 [INFO] [lib.training._xgboost_pretrained:590] Loading pretrained model: vit_gru (num_frames=400)
2025-12-18 10:45:56 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-18 10:45:57 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-18 10:45:57 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-18 10:45:58 [INFO] [lib.training._xgboost_pretrained:605] Loaded vit_gru model to GPU, cleared cache
2025-12-18 10:45:58 [INFO] [lib.training._xgboost_pretrained:622] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-18 10:45:58 [INFO] [lib.training._xgboost_pretrained:672] Extracting features using vit_gru (num_frames=400)...
2025-12-18 10:45:58 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-18 11:32:36 [INFO] [lib.training._xgboost_pretrained:478] Extracted features shape: (655, 3072)
2025-12-18 11:32:36 [INFO] [lib.training._xgboost_pretrained:690] Cleared vit_gru model from GPU after feature extraction
2025-12-18 11:32:36 [INFO] [lib.training.pipeline:500] Fold 4 - Val Loss: 0.0447, Val Acc: 0.9969, Val F1: 0.9970, Val Precision: 0.9970, Val Recall: 0.9970
2025-12-18 11:32:36 [INFO] [lib.training._xgboost_pretrained:908] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_4
2025-12-18 11:32:36 [INFO] [lib.training.pipeline:516] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_4
2025-12-18 11:32:37 [INFO] [lib.training.visualization:480] Generated fold 4 plots: ROC/PR curves and confusion matrix
2025-12-18 11:32:38 [INFO] [lib.training.pipeline:2123] 
Final Training - xgboost_vit_gru - Fold 5/5 (full dataset)
2025-12-18 11:32:38 [INFO] [lib.training.pipeline:2131] Deleted existing final training fold 5 directory (clean mode)
2025-12-18 11:32:38 [INFO] [lib.training.pipeline:448] Training XGBoost model xgboost_vit_gru on fold 5...
2025-12-18 11:32:38 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost on features from vit_gru...
2025-12-18 11:32:38 [INFO] [lib.training._xgboost_pretrained:705] Processing 2622 videos...
2025-12-18 11:32:38 [INFO] [lib.training._xgboost_pretrained:590] Loading pretrained model: vit_gru (num_frames=400)
2025-12-18 11:32:39 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-18 11:32:39 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-18 11:32:39 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-18 11:32:39 [INFO] [lib.training._xgboost_pretrained:605] Loaded vit_gru model to GPU, cleared cache
2025-12-18 11:32:39 [INFO] [lib.training._xgboost_pretrained:622] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-18 11:32:39 [INFO] [lib.training._xgboost_pretrained:672] Extracting features using vit_gru (num_frames=400)...
2025-12-18 11:32:39 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-18 14:37:08 [INFO] [lib.training._xgboost_pretrained:478] Extracted features shape: (2622, 3072)
2025-12-18 14:37:09 [INFO] [lib.training._xgboost_pretrained:690] Cleared vit_gru model from GPU after feature extraction
2025-12-18 14:37:09 [INFO] [lib.training._xgboost_pretrained:728] Removing collinear features...
2025-12-18 14:37:09 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-18 14:37:11 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-18 14:37:11 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-18 14:37:11 [INFO] [lib.training._xgboost_pretrained:735] Using 3072 features after collinearity removal
2025-12-18 14:37:11 [INFO] [lib.training._xgboost_pretrained:751] Class distribution: Class 0=1284, Class 1=1338, scale_pos_weight=0.960
2025-12-18 14:37:11 [INFO] [lib.training._xgboost_pretrained:769] Training XGBoost: 2097 train samples, 525 validation samples for early stopping
2025-12-18 14:37:11 [INFO] [lib.training._xgboost_pretrained:772] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-18 14:38:06 [INFO] [lib.training._xgboost_pretrained:838] Early stopping: Best iteration = 200 (out of 200)
2025-12-18 14:38:06 [INFO] [lib.training._xgboost_pretrained:840] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-18 14:38:07 [INFO] [lib.training._xgboost_pretrained:590] Loading pretrained model: vit_gru (num_frames=400)
2025-12-18 14:38:08 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-18 14:38:08 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-18 14:38:08 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-18 14:38:08 [INFO] [lib.training._xgboost_pretrained:605] Loaded vit_gru model to GPU, cleared cache
2025-12-18 14:38:08 [INFO] [lib.training._xgboost_pretrained:622] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-18 14:38:08 [INFO] [lib.training._xgboost_pretrained:672] Extracting features using vit_gru (num_frames=400)...
2025-12-18 14:38:08 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-18 15:23:48 [INFO] [lib.training._xgboost_pretrained:478] Extracted features shape: (655, 3072)
2025-12-18 15:23:49 [INFO] [lib.training._xgboost_pretrained:690] Cleared vit_gru model from GPU after feature extraction
2025-12-18 15:23:49 [INFO] [lib.training.pipeline:500] Fold 5 - Val Loss: 0.0463, Val Acc: 0.9985, Val F1: 0.9985, Val Precision: 1.0000, Val Recall: 0.9970
2025-12-18 15:23:49 [INFO] [lib.training._xgboost_pretrained:908] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_5
2025-12-18 15:23:49 [INFO] [lib.training.pipeline:516] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_5
2025-12-18 15:23:50 [INFO] [lib.training.visualization:480] Generated fold 5 plots: ROC/PR curves and confusion matrix
2025-12-18 15:23:51 [INFO] [lib.training.pipeline:107] Saved best model from fold 5: Copied 2 model file(s) from fold_5 to best_model
2025-12-18 15:23:51 [INFO] [lib.training.pipeline:2348] 
xgboost_vit_gru - Avg Val Loss: 0.0467 ± 0.0027, Avg Val Acc: 0.9960 ± 0.0021, Avg Val F1: 0.9961 ± 0.0020
2025-12-18 15:23:51 [INFO] [lib.training.pipeline:2352]   Avg Val Precision: 0.9970 ± 0.0019, Avg Val Recall: 0.9952 ± 0.0024
2025-12-18 15:23:51 [INFO] [lib.training.pipeline:2356]   Class 0 - F1: 0.9960 ± 0.0021, Precision: 0.9950 ± 0.0025, Recall: 0.9969 ± 0.0020
2025-12-18 15:23:51 [INFO] [lib.training.pipeline:2361]   Class 1 - F1: 0.9961 ± 0.0020, Precision: 0.9970 ± 0.0019, Recall: 0.9952 ± 0.0024
2025-12-18 15:23:51 [INFO] [lib.training.pipeline:2399] Saved aggregated metrics to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/metrics.json (model: xgboost_vit_gru)
2025-12-18 15:23:52 [INFO] [lib.training.visualization:256] Saved CV fold comparison to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/plots/cv_fold_comparison.png
2025-12-18 15:23:52 [INFO] [lib.training.pipeline:2426] Generated plots for xgboost_vit_gru in /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/plots
2025-12-18 15:23:53 [INFO] [lib.training.pipeline:2463] ================================================================================
2025-12-18 15:23:53 [INFO] [lib.training.pipeline:2464] Stage 5: Model Training Pipeline Completed
2025-12-18 15:23:53 [INFO] [lib.training.pipeline:2465] ================================================================================
2025-12-18 15:23:53 [INFO] [__main__:401] ================================================================================
2025-12-18 15:23:53 [INFO] [__main__:402] STAGE 5 COMPLETED SUCCESSFULLY
2025-12-18 15:23:53 [INFO] [__main__:403] ================================================================================
2025-12-18 15:23:53 [INFO] [__main__:404] Execution time: 77889.62 seconds (1298.16 minutes)
2025-12-18 15:23:53 [INFO] [__main__:406] Output directory: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-18 15:23:53 [INFO] [__main__:407] Models trained: ['xgboost_vit_gru']
2025-12-18 15:23:53 [INFO] [__main__:408] K-fold splits: 5
2025-12-18 15:23:53 [INFO] [__main__:414] ================================================================================
2025-12-18 15:23:53 [INFO] [__main__:415] Final memory statistics:
2025-12-18 15:23:53 [INFO] [__main__:416] ================================================================================
2025-12-18 15:23:53 [INFO] [lib.utils.memory:91] Memory stats (Stage 5: after training): {'cpu_memory_mb': 12366.89453125, 'cpu_memory_gb': 12.077045440673828, 'cpu_vms_mb': 59914.2890625, 'gpu_allocated_gb': 0.009568256, 'gpu_reserved_gb': 0.046137344, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 16.882204672}
2025-12-18 15:23:53 [INFO] [__main__:419] ================================================================================
2025-12-18 15:23:53 [INFO] [__main__:420] Training complete!
2025-12-18 15:23:53 [INFO] [__main__:421] Results saved to: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-18 15:23:53 [INFO] [__main__:422] ================================================================================

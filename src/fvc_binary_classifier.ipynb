{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FVC Binary Video Classifier\n",
    "\n",
    "This notebook wires together the FVC video library to:\n",
    "\n",
    "1. Run `setup_fvc_dataset.py` to prepare the dataset.\n",
    "2. Build augmented train/val loaders.\n",
    "3. Train the variable-aspect-ratio 3D CNN binary classifier.\n",
    "4. Log metrics and save intermediates/checkpoints.\n",
    "\n",
    "All warnings are captured into the Python logger so they are logged but do not stop execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import warnings\n",
    "import subprocess\n",
    "\n",
    "# Configure logging (Python 3.6 compatible - no force=True)\n",
    "# Clear existing handlers to allow reconfiguration\n",
    "root_logger = logging.getLogger()\n",
    "for handler in root_logger.handlers[:]:\n",
    "    root_logger.removeHandler(handler)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\",\n",
    ")\n",
    "logger = logging.getLogger(\"fvc_notebook\")\n",
    "\n",
    "# Capture Python warnings into logging\n",
    "logging.captureWarnings(True)\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "# Detect project root: look for src/fvc_binary_classifier.ipynb in parent dirs\n",
    "# or use SLURM_SUBMIT_DIR if available, or current working directory\n",
    "if \"SLURM_SUBMIT_DIR\" in os.environ:\n",
    "    PROJECT_ROOT = os.environ[\"SLURM_SUBMIT_DIR\"]\n",
    "elif \"SLURM_TMPDIR\" in os.environ:\n",
    "    # If running in TMPDIR, project was copied there\n",
    "    PROJECT_ROOT = os.environ[\"SLURM_TMPDIR\"]\n",
    "else:\n",
    "    # Fallback: assume we're in project root or one level down\n",
    "    cwd = os.getcwd()\n",
    "    if os.path.exists(os.path.join(cwd, \"src\", \"fvc_binary_classifier.ipynb\")):\n",
    "        PROJECT_ROOT = cwd\n",
    "    elif os.path.exists(os.path.join(cwd, \"..\", \"src\", \"fvc_binary_classifier.ipynb\")):\n",
    "        PROJECT_ROOT = os.path.dirname(cwd)\n",
    "    else:\n",
    "        PROJECT_ROOT = cwd\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(PROJECT_ROOT)\n",
    "DATA_CSV = os.path.join(PROJECT_ROOT, \"data\", \"video_index_input.csv\")\n",
    "INTERMEDIATE_DIR = os.path.join(PROJECT_ROOT, \"data\", \"intermediates\")\n",
    "MODELS_DIR = os.path.join(PROJECT_ROOT, \"models\")\n",
    "\n",
    "os.makedirs(INTERMEDIATE_DIR, exist_ok=True)\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "logger.info(\"Python version: %s\", sys.version)\n",
    "logger.info(\"Python version info: %s.%s.%s\", sys.version_info.major, sys.version_info.minor, sys.version_info.micro)\n",
    "\n",
    "# Check Python version compatibility\n",
    "if sys.version_info < (3, 6):\n",
    "    logger.error(\"Python 3.6+ required, found %s.%s\", sys.version_info.major, sys.version_info.minor)\n",
    "    raise RuntimeError(\"Python 3.6+ required\")\n",
    "\n",
    "# Check for dataclasses (Python 3.7+)\n",
    "try:\n",
    "    from dataclasses import dataclass\n",
    "    logger.info(\"\u2713 dataclasses module available\")\n",
    "except ImportError:\n",
    "    logger.error(\"dataclasses module not available (requires Python 3.7+)\")\n",
    "    raise RuntimeError(\"dataclasses module required but not available\")\n",
    "\n",
    "logger.info(\"Current working directory: %s\", os.getcwd())\n",
    "logger.info(\"Project root: %s\", PROJECT_ROOT)\n",
    "logger.info(\"Data CSV: %s\", DATA_CSV)\n",
    "logger.info(\"Intermediates dir: %s\", INTERMEDIATE_DIR)\n",
    "logger.info(\"Models dir: %s\", MODELS_DIR)\n",
    "\n",
    "# Verify critical files exist\n",
    "if not os.path.exists(DATA_CSV):\n",
    "    logger.error(\"Data CSV not found at %s\", DATA_CSV)\n",
    "    raise FileNotFoundError(\"Data CSV not found: {}\".format(DATA_CSV))\n",
    "logger.info(\"\u2713 Data CSV exists\")\n",
    "\n",
    "# Verify required packages are importable\n",
    "try:\n",
    "    import polars as pl\n",
    "    import torch\n",
    "    logger.info(\"\u2713 Core packages (polars, torch) importable\")\n",
    "except ImportError as e:\n",
    "    logger.error(\"Failed to import required package: %s\", e)\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Run setup_fvc_dataset.py to prepare the dataset\n",
    "\n",
    "try:\n",
    "    logger.info(\"Running setup_fvc_dataset.py...\")\n",
    "    # Python 3.6 compatible: use stdout/stderr instead of capture_output\n",
    "    result = subprocess.run(\n",
    "        [\"python\", os.path.join(PROJECT_ROOT, \"src\", \"setup_fvc_dataset.py\")],\n",
    "        check=True,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "    )\n",
    "    # Decode bytes to string (Python 3.6 compatible)\n",
    "    stdout_text = result.stdout.decode('utf-8') if result.stdout else \"\"\n",
    "    stderr_text = result.stderr.decode('utf-8') if result.stderr else \"\"\n",
    "    \n",
    "    logger.info(\"setup_fvc_dataset.py stdout:\\n%s\", stdout_text)\n",
    "    if stderr_text:\n",
    "        logger.warning(\"setup_fvc_dataset.py stderr:\\n%s\", stderr_text)\n",
    "    logger.info(\"setup_fvc_dataset.py completed successfully.\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    stdout_text = e.stdout.decode('utf-8') if e.stdout else \"\"\n",
    "    stderr_text = e.stderr.decode('utf-8') if e.stderr else \"\"\n",
    "    logger.error(\"setup_fvc_dataset.py failed with return code %s\", e.returncode)\n",
    "    logger.error(\"stdout:\\n%s\", stdout_text)\n",
    "    logger.error(\"stderr:\\n%s\", stderr_text)\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Build augmented train/val loaders using the FVC video library\n",
    "\n",
    "import polars as pl\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from lib.video_data import SplitConfig, load_metadata, train_val_test_split, filter_existing_videos, make_balanced_batch_sampler\n",
    "from lib.video_modeling import VideoConfig, VideoDataset, variable_ar_collate\n",
    "from lib.video_training import OptimConfig, TrainConfig, fit\n",
    "from lib.video_augmentation_pipeline import pregenerate_augmented_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "logger.info(\"Loading metadata with Polars from %s\", DATA_CSV)\n",
    "meta_df = load_metadata(DATA_CSV)\n",
    "logger.info(\"Metadata rows: %d\", meta_df.height)\n",
    "\n",
    "# Filter out missing video files before splitting\n",
    "logger.info(\"Filtering out missing video files...\")\n",
    "try:\n",
    "    meta_df_filtered = filter_existing_videos(meta_df, PROJECT_ROOT)\n",
    "    missing_count = meta_df.height - meta_df_filtered.height\n",
    "    if missing_count > 0:\n",
    "        logger.warning(\"Filtered out %d missing video files (keeping %d)\", missing_count, meta_df_filtered.height)\n",
    "    else:\n",
    "        logger.info(\"All %d video files exist\", meta_df_filtered.height)\n",
    "except ValueError as e:\n",
    "    logger.error(\"Failed to filter videos: %s\", str(e))\n",
    "    logger.error(\"Cannot proceed with training - no valid videos found.\")\n",
    "    raise\n",
    "\n",
    "# Validate we have enough videos for training\n",
    "if meta_df_filtered.height < 2:\n",
    "    raise ValueError(\n",
    "        f\"Not enough videos for training. Found {meta_df_filtered.height} videos, \"\n",
    "        f\"but need at least 2 (one for train, one for val).\"\n",
    "    )\n",
    "\n",
    "splits = train_val_test_split(\n",
    "    meta_df_filtered,\n",
    "    SplitConfig(val_size=0.2, test_size=0.0),\n",
    "    save_dir=INTERMEDIATE_DIR,\n",
    ")\n",
    "train_df = splits[\"train\"]\n",
    "val_df = splits[\"val\"]\n",
    "\n",
    "logger.info(\"Train rows: %d, Val rows: %d\", train_df.height, val_df.height)\n",
    "\n",
    "# Final validation before creating datasets\n",
    "if train_df.height == 0:\n",
    "    raise ValueError(\"Train dataset is empty after filtering. Cannot create DataLoader.\")\n",
    "if val_df.height == 0:\n",
    "    logger.warning(\"Validation dataset is empty. Consider reducing val_size or checking data splits.\")\n",
    "\n",
    "# GPU-optimized configuration with comprehensive augmentations\n",
    "# Strategy: Fixed-size downscaling + comprehensive augmentations for better generalization\n",
    "# Using fixed_size=224 ensures all videos have 224x224 dimensions (with letterboxing for aspect ratio)\n",
    "# Comprehensive augmentations include: geometric, color, noise, blur, cutout, and temporal augmentations\n",
    "video_cfg = VideoConfig(\n",
    "    num_frames=16,  # Increased back to 16 - fixed_size=224 makes this memory-efficient\n",
    "    fixed_size=224,  # Fixed 224x224 size with letterboxing (maintains aspect ratio, no padding needed)\n",
    "    # Comprehensive spatial augmentations\n",
    "    augmentation_config={\n",
    "        'rotation_degrees': 15.0,  # Small rotations\n",
    "        'rotation_p': 0.5,\n",
    "        'affine_p': 0.3,  # Translation, scale, shear\n",
    "        'gaussian_noise_std': 0.1,  # Noise injection\n",
    "        'gaussian_noise_p': 0.3,\n",
    "        'gaussian_blur_p': 0.3,  # Blur augmentation\n",
    "        'cutout_p': 0.5,  # Random erasing\n",
    "        'cutout_max_size': 32,  # Max cutout size\n",
    "        'elastic_transform_p': 0.2,  # Elastic deformation\n",
    "        'color_jitter_brightness': 0.3,  # Enhanced color jitter\n",
    "        'color_jitter_contrast': 0.3,\n",
    "        'color_jitter_saturation': 0.3,\n",
    "        'color_jitter_hue': 0.1,\n",
    "    },\n",
    "    # Temporal augmentations\n",
    "    temporal_augmentation_config={\n",
    "        'frame_drop_prob': 0.1,  # Randomly drop frames\n",
    "        'frame_dup_prob': 0.1,  # Randomly duplicate frames (slow motion)\n",
    "        'reverse_prob': 0.1,  # Reverse temporal order\n",
    "    }\n",
    ")\n",
    "logger.info(\"Video config: num_frames=%d, fixed_size=%s (GPU-optimized with comprehensive augmentations)\", \n",
    "            video_cfg.num_frames, video_cfg.fixed_size)\n",
    "logger.info(\"Augmentations enabled: geometric, color, noise, blur, cutout, temporal\")\n",
    "\n",
    "# STEP 1: Pre-generate augmented clips BEFORE training\n",
    "# This stores augmented data on disk, making training faster and more reproducible\n",
    "AUGMENTED_DATA_DIR = os.path.join(INTERMEDIATE_DIR, \"augmented_clips\")\n",
    "NUM_AUGMENTATIONS_PER_VIDEO = 3  # Generate 3 augmented versions per video\n",
    "\n",
    "logger.info(\"=\" * 80)\n",
    "logger.info(\"STEP 1: Pre-generating augmented clips...\")\n",
    "logger.info(\"This will create %d augmented versions per training video\", NUM_AUGMENTATIONS_PER_VIDEO)\n",
    "logger.info(\"Output directory: %s\", AUGMENTED_DATA_DIR)\n",
    "\n",
    "try:\n",
    "    # Check if augmented data already exists\n",
    "    if os.path.exists(AUGMENTED_DATA_DIR) and len(list(Path(AUGMENTED_DATA_DIR).glob(\"*.pt\"))) > 0:\n",
    "        logger.info(\"\u2713 Augmented clips already exist. Skipping generation.\")\n",
    "        logger.info(\"  To regenerate, delete: %s\", AUGMENTED_DATA_DIR)\n",
    "        # Load existing augmented dataset metadata\n",
    "        augmented_train_df = pl.read_csv(os.path.join(AUGMENTED_DATA_DIR, \"augmented_train_metadata.csv\"))\n",
    "        logger.info(\"Loaded %d pre-generated augmented clips\", augmented_train_df.height)\n",
    "    else:\n",
    "        logger.info(\"Generating augmented clips (this may take a while)...\")\n",
    "        augmented_train_df = pregenerate_augmented_dataset(\n",
    "            train_df,\n",
    "            PROJECT_ROOT,\n",
    "            video_cfg,\n",
    "            output_dir=AUGMENTED_DATA_DIR,\n",
    "            num_augmentations_per_video=NUM_AUGMENTATIONS_PER_VIDEO,\n",
    "        )\n",
    "        \n",
    "        # Save metadata for future use\n",
    "        metadata_path = os.path.join(AUGMENTED_DATA_DIR, \"augmented_train_metadata.csv\")\n",
    "        augmented_train_df.write_csv(metadata_path)\n",
    "        logger.info(\"\u2713 Generated %d augmented clips\", augmented_train_df.height)\n",
    "        logger.info(\"\u2713 Saved metadata to: %s\", metadata_path)\n",
    "    \n",
    "    # Use augmented dataset for training\n",
    "    train_df_final = augmented_train_df\n",
    "    logger.info(\"Using pre-generated augmented clips for training\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(\"Failed to pre-generate augmentations: %s\", str(e))\n",
    "    logger.warning(\"Falling back to on-the-fly augmentations during training\")\n",
    "    train_df_final = train_df\n",
    "\n",
    "logger.info(\"=\" * 80)\n",
    "\n",
    "# STEP 2: Create datasets\n",
    "# Training dataset: use pre-generated augmented clips (or fallback to on-the-fly)\n",
    "# Validation dataset: use original videos (no augmentation)\n",
    "train_ds = VideoDataset(train_df_final, PROJECT_ROOT, config=video_cfg, train=False)  # train=False since augmentations are pre-generated\n",
    "val_ds = VideoDataset(val_df, PROJECT_ROOT, config=video_cfg, train=False)  # No augmentation for validation\n",
    "\n",
    "logger.info(\"Train dataset: %d samples (pre-generated augmentations)\", len(train_ds))\n",
    "logger.info(\"Val dataset: %d samples (original videos)\", len(val_ds))\n",
    "\n",
    "# GPU-optimized: With fixed_size=224, we can use much larger batch sizes\n",
    "# Progressive batch size strategy to fully utilize GPU memory\n",
    "# Priority: batch_size=32 -> 16 -> 8 -> 4 (with balanced sampling)\n",
    "num_workers = 4  # Enable parallel data loading for better throughput\n",
    "pin_memory = torch.cuda.is_available()  # Enable pin_memory for faster GPU transfers\n",
    "\n",
    "# Try larger batch sizes first (fixed_size=224 makes this feasible)\n",
    "batch_size = 32  # Start with 32 (16 real + 16 fake per batch) - aggressive but feasible with 224x224\n",
    "samples_per_class = batch_size // 2\n",
    "\n",
    "try:\n",
    "    # Create balanced batch sampler (ensures equal real/fake per batch)\n",
    "    # Use train_df_final (which contains pre-generated augmentations) instead of train_df\n",
    "    balanced_sampler = make_balanced_batch_sampler(\n",
    "        train_df_final,  # Use augmented dataset\n",
    "        batch_size=batch_size,\n",
    "        samples_per_class=samples_per_class,\n",
    "        shuffle=True,\n",
    "        random_state=42,\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_sampler=balanced_sampler,  # Use batch_sampler instead of batch_size\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,  # Enable for faster GPU transfers\n",
    "        collate_fn=variable_ar_collate,\n",
    "        persistent_workers=True if num_workers > 0 else False,  # Keep workers alive for efficiency\n",
    "        prefetch_factor=2 if num_workers > 0 else None,  # Prefetch batches for better throughput\n",
    "    )\n",
    "    \n",
    "    logger.info(\"\u2713 Using balanced batch sampler: %d samples per class per batch (batch_size=%d)\", \n",
    "                samples_per_class, batch_size)\n",
    "    logger.info(\"\u26a0 If you encounter OOM, the code will automatically fallback to smaller batch sizes\")\n",
    "    \n",
    "except (ValueError, RuntimeError) as e:\n",
    "    logger.warning(\"\u26a0 Balanced batch sampling with batch_size=32 failed: %s. Trying batch_size=16...\", str(e))\n",
    "    # Fallback 1: Try batch_size=16 (8 real + 8 fake)\n",
    "    batch_size = 16\n",
    "    samples_per_class = 8\n",
    "    \n",
    "    try:\n",
    "        balanced_sampler = make_balanced_batch_sampler(\n",
    "            train_df,\n",
    "            batch_size=batch_size,\n",
    "            samples_per_class=samples_per_class,\n",
    "            shuffle=True,\n",
    "            random_state=42,\n",
    "        )\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            train_ds,\n",
    "            batch_sampler=balanced_sampler,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=pin_memory,\n",
    "            collate_fn=variable_ar_collate,\n",
    "            persistent_workers=True if num_workers > 0 else False,\n",
    "            prefetch_factor=2 if num_workers > 0 else None,\n",
    "        )\n",
    "        \n",
    "        logger.info(\"\u2713 Using balanced batch sampler: %d samples per class per batch (batch_size=%d)\", \n",
    "                    samples_per_class, batch_size)\n",
    "        logger.info(\"\u26a0 If you encounter OOM, the code will automatically fallback to batch_size=8\")\n",
    "        \n",
    "    except (ValueError, RuntimeError) as e2:\n",
    "        logger.warning(\"\u26a0 Balanced batch sampling with batch_size=16 failed: %s. Trying batch_size=8...\", str(e2))\n",
    "        # Fallback 2: Try batch_size=8 (4 real + 4 fake)\n",
    "        batch_size = 8\n",
    "        samples_per_class = 4\n",
    "        \n",
    "        try:\n",
    "            balanced_sampler = make_balanced_batch_sampler(\n",
    "                train_df,\n",
    "                batch_size=batch_size,\n",
    "                samples_per_class=samples_per_class,\n",
    "                shuffle=True,\n",
    "                random_state=42,\n",
    "            )\n",
    "            \n",
    "            train_loader = DataLoader(\n",
    "                train_ds,\n",
    "                batch_sampler=balanced_sampler,\n",
    "                num_workers=num_workers,\n",
    "                pin_memory=pin_memory,\n",
    "                collate_fn=variable_ar_collate,\n",
    "                persistent_workers=True if num_workers > 0 else False,\n",
    "                prefetch_factor=2 if num_workers > 0 else None,\n",
    "            )\n",
    "            \n",
    "            logger.info(\"\u2713 Using balanced batch sampler: %d samples per class per batch (batch_size=%d)\", \n",
    "                        samples_per_class, batch_size)\n",
    "            logger.info(\"\u26a0 If you encounter OOM, the code will automatically fallback to batch_size=4\")\n",
    "            \n",
    "        except (ValueError, RuntimeError) as e3:\n",
    "            logger.warning(\"\u26a0 Balanced batch sampling with batch_size=8 failed: %s. Trying batch_size=4...\", str(e3))\n",
    "            # Fallback 3: Try batch_size=4 (2 real + 2 fake)\n",
    "            batch_size = 4\n",
    "            samples_per_class = 2\n",
    "            \n",
    "            try:\n",
    "                balanced_sampler = make_balanced_batch_sampler(\n",
    "                    train_df,\n",
    "                    batch_size=batch_size,\n",
    "                    samples_per_class=samples_per_class,\n",
    "                    shuffle=True,\n",
    "                    random_state=42,\n",
    "                )\n",
    "                \n",
    "                train_loader = DataLoader(\n",
    "                    train_ds,\n",
    "                    batch_sampler=balanced_sampler,\n",
    "                    num_workers=num_workers,\n",
    "                    pin_memory=pin_memory,\n",
    "                    collate_fn=variable_ar_collate,\n",
    "                    persistent_workers=True if num_workers > 0 else False,\n",
    "                    prefetch_factor=2 if num_workers > 0 else None,\n",
    "                )\n",
    "                \n",
    "                logger.info(\"\u2713 Using balanced batch sampler: %d samples per class per batch (batch_size=%d)\", \n",
    "                            samples_per_class, batch_size)\n",
    "                logger.info(\"\u26a0 If you encounter OOM, the code will automatically fallback to batch_size=2\")\n",
    "                \n",
    "            except (ValueError, RuntimeError) as e4:\n",
    "                logger.warning(\"\u26a0 Balanced batch sampling with batch_size=4 failed: %s. Using batch_size=2...\", str(e4))\n",
    "                # Fallback 4: Try batch_size=2 (1 real + 1 fake)\n",
    "                batch_size = 2\n",
    "                samples_per_class = 1\n",
    "                \n",
    "                try:\n",
    "                    balanced_sampler = make_balanced_batch_sampler(\n",
    "                        train_df,\n",
    "                        batch_size=batch_size,\n",
    "                        samples_per_class=samples_per_class,\n",
    "                        shuffle=True,\n",
    "                        random_state=42,\n",
    "                    )\n",
    "                    \n",
    "                    train_loader = DataLoader(\n",
    "                        train_ds,\n",
    "                        batch_sampler=balanced_sampler,\n",
    "                        num_workers=num_workers,\n",
    "                        pin_memory=pin_memory,\n",
    "                        collate_fn=variable_ar_collate,\n",
    "                        persistent_workers=True if num_workers > 0 else False,\n",
    "                        prefetch_factor=2 if num_workers > 0 else None,\n",
    "                    )\n",
    "                    \n",
    "                    logger.info(\"\u2713 Using balanced batch sampler: %d samples per class per batch (batch_size=%d)\", \n",
    "                                samples_per_class, batch_size)\n",
    "                    logger.warning(\"\u26a0 Using small batch_size=2. Consider reducing num_frames if OOM occurs.\")\n",
    "                    \n",
    "                except (ValueError, RuntimeError) as e5:\n",
    "                    logger.warning(\"\u26a0 Balanced batch sampling with batch_size=2 failed: %s. Using batch_size=1 with gradient accumulation...\", str(e5))\n",
    "                    # Final fallback: Use batch_size=1 with gradient accumulation\n",
    "                    batch_size = 1\n",
    "                    train_loader = DataLoader(\n",
    "                        train_ds,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        num_workers=num_workers,\n",
    "                        pin_memory=pin_memory,\n",
    "                        collate_fn=variable_ar_collate,\n",
    "                        persistent_workers=False,\n",
    "                        prefetch_factor=None,\n",
    "                    )\n",
    "                    logger.warning(\"\u26a0 Using batch_size=1 (unbalanced batches). Gradient accumulation will be used to simulate larger batches.\")\n",
    "\n",
    "# Validation loader (always use regular sampling, no need for balanced batches)\n",
    "# Use same batch_size as training for consistency (fixed_size=224 makes this feasible)\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=batch_size,  # Use same batch_size as training (fixed_size enables this)\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    collate_fn=variable_ar_collate,\n",
    "    persistent_workers=True if num_workers > 0 else False,\n",
    "    prefetch_factor=2 if num_workers > 0 else None,\n",
    ")\n",
    "\n",
    "logger.info(\"Data loaders ready: %d train batches, %d val batches\", len(train_loader), len(val_loader))\n",
    "logger.info(\"Final config: batch_size=%d, num_frames=%d, num_workers=%d\", \n",
    "            batch_size, video_cfg.num_frames, num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Train the binary classifier (pretrained 3D ResNet backbone + Inception head)\n",
    "\n",
    "from lib.video_modeling import PretrainedInceptionVideoModel\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "logger.info(\"Using device: %s\", device)\n",
    "\n",
    "# Clear CUDA cache before loading model\n",
    "if device.startswith(\"cuda\"):\n",
    "    torch.cuda.empty_cache()\n",
    "    logger.info(\"CUDA memory cleared. Free: %.2f GB\", \n",
    "                torch.cuda.get_device_properties(0).total_memory / 1e9 - \n",
    "                torch.cuda.memory_allocated(0) / 1e9)\n",
    "\n",
    "# Use pretrained r3d_18 backbone with an Inception-like head.\n",
    "# Backbone layers are frozen by default; only the head is trained.\n",
    "model = PretrainedInceptionVideoModel(freeze_backbone=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# Clear cache after model loading\n",
    "if device.startswith(\"cuda\"):\n",
    "    torch.cuda.empty_cache()\n",
    "    logger.info(\"Model loaded. CUDA memory allocated: %.2f GB\", \n",
    "                torch.cuda.memory_allocated(0) / 1e9)\n",
    "\n",
    "optim_cfg = OptimConfig(lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "# Adjust gradient accumulation based on actual batch_size\n",
    "# With larger batch sizes enabled by fixed_size=224, we typically don't need accumulation\n",
    "# Only use accumulation for very small batch sizes\n",
    "if batch_size >= 8:\n",
    "    # Large batches: no accumulation needed\n",
    "    gradient_accumulation_steps = 1\n",
    "    effective_batch_size = batch_size\n",
    "elif batch_size >= 4:\n",
    "    # Medium batches: minimal accumulation for stability\n",
    "    gradient_accumulation_steps = 1\n",
    "    effective_batch_size = batch_size\n",
    "elif batch_size >= 2:\n",
    "    # Small batches: use accumulation to simulate larger effective batch\n",
    "    gradient_accumulation_steps = 2\n",
    "    effective_batch_size = batch_size * gradient_accumulation_steps\n",
    "else:\n",
    "    # Very small batch_size=1: use more accumulation\n",
    "    gradient_accumulation_steps = 4\n",
    "    effective_batch_size = batch_size * gradient_accumulation_steps\n",
    "\n",
    "train_cfg = TrainConfig(\n",
    "    num_epochs=10,\n",
    "    device=device,\n",
    "    log_interval=10,\n",
    "    use_class_weights=True,\n",
    "    use_amp=True,\n",
    "    checkpoint_dir=MODELS_DIR,\n",
    "    early_stopping_patience=3,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    ")\n",
    "\n",
    "if gradient_accumulation_steps > 1:\n",
    "    logger.info(\"Using gradient accumulation: %d steps (effective batch_size=%d)\", \n",
    "                gradient_accumulation_steps, effective_batch_size)\n",
    "else:\n",
    "    logger.info(\"Using balanced batches: batch_size=%d (no gradient accumulation needed)\", \n",
    "                batch_size)\n",
    "\n",
    "logger.info(\"Starting training with pretrained backbone...\")\n",
    "\n",
    "# Set memory management environment variables\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# Monitor initial memory\n",
    "if device.startswith(\"cuda\"):\n",
    "    torch.cuda.empty_cache()\n",
    "    allocated = torch.cuda.memory_allocated(0) / 1e9\n",
    "    reserved = torch.cuda.memory_reserved(0) / 1e9\n",
    "    total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    logger.info(\"GPU memory before training: %.2f GB allocated, %.2f GB reserved, %.2f GB total\", \n",
    "                allocated, reserved, total)\n",
    "\n",
    "try:\n",
    "    model = fit(\n",
    "        model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        optim_cfg=optim_cfg,\n",
    "        train_cfg=train_cfg,\n",
    "    )\n",
    "    logger.info(\"Training completed successfully.\")\n",
    "except RuntimeError as e:\n",
    "    if \"out of memory\" in str(e).lower() or \"OOM\" in str(e):\n",
    "        logger.error(\"CUDA OOM error during training: %s\", str(e))\n",
    "        if device.startswith(\"cuda\"):\n",
    "            torch.cuda.empty_cache()\n",
    "            allocated = torch.cuda.memory_allocated(0) / 1e9\n",
    "            logger.error(\"GPU memory after OOM: %.2f GB still allocated\", allocated)\n",
    "        logger.error(\"Suggestions:\")\n",
    "        logger.error(\"  1. Reduce batch_size further (currently %d)\", batch_size)\n",
    "        logger.error(\"  2. Reduce num_frames further (currently %d)\", video_cfg.num_frames)\n",
    "        logger.error(\"  3. Use gradient accumulation to simulate larger batches\")\n",
    "        logger.error(\"  4. Consider using a smaller model\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    logger.exception(\"Training failed with exception: %s\", e)\n",
    "    raise\n",
    "finally:\n",
    "    # Clean up memory\n",
    "    if device.startswith(\"cuda\"):\n",
    "        torch.cuda.empty_cache()\n",
    "        logger.info(\"GPU memory cleaned up after training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Evaluate on validation set and log metrics\n",
    "\n",
    "from lib.video_metrics import collect_logits_and_labels, basic_classification_metrics, confusion_matrix, roc_auc\n",
    "\n",
    "logger.info(\"Evaluating model on validation set...\")\n",
    "\n",
    "try:\n",
    "    logits, labels = collect_logits_and_labels(model, val_loader, device=device)\n",
    "    metrics = basic_classification_metrics(logits, labels)\n",
    "    cm = confusion_matrix(logits, labels)\n",
    "    auc = roc_auc(logits, labels)\n",
    "\n",
    "    logger.info(\"Validation metrics: %s\", metrics)\n",
    "    logger.info(\"Validation ROC-AUC: %.4f\", auc)\n",
    "    logger.info(\"Confusion matrix:\\n%s\", cm.numpy())\n",
    "except Exception as e:\n",
    "    logger.exception(\"Evaluation failed with exception: %s\", e)\n",
    "    raise\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
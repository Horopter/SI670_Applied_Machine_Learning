{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5b: Support Vector Machine (SVM)\n",
    "\n",
    "This notebook demonstrates the SVM model for deepfake video detection.\n",
    "\n",
    "## Model Overview\n",
    "\n",
    "Support Vector Machine is a baseline feature-based model that uses handcrafted features extracted from videos (Stage 2 features). It uses kernel methods to find optimal decision boundaries.\n",
    "\n",
    "## Training Instructions\n",
    "\n",
    "To train this model, run:\n",
    "\n",
    "```bash\n",
    "sbatch src/scripts/slurm_stage5b.sh\n",
    "```\n",
    "\n",
    "Or use Python:\n",
    "\n",
    "```python\n",
    "from lib.training.pipeline import stage5_train_models\n",
    "\n",
    "results = stage5_train_models(\n",
    "    project_root=\".\",\n",
    "    scaled_metadata_path=\"data/stage3/scaled_metadata.parquet\",\n",
    "    features_stage2_path=\"data/stage2/features_metadata.parquet\",\n",
    "    features_stage4_path=None,\n",
    "    model_types=[\"svm\"],\n",
    "    n_splits=5,\n",
    "    num_frames=1000,\n",
    "    output_dir=\"data/stage5\",\n",
    "    use_tracking=True,\n",
    "    use_mlflow=True\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture Deep-Dive\n\n",
    "**svm** architecture details.\n\n",
    "See model implementation in `lib/training/` for specific architecture code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Configuration\n\n",
    "**Training Hyperparameters** (from `lib/training/grid_search.py`):\n\n",
    "- **C**: [0.1, 1.0, 10.0] (grid search)\n",
    "- **kernel**: ['linear', 'rbf'] (grid search)\n",
    "\n**Rationale**:\n",
    "- **Single Hyperparameter Combination**: Reduced from multiple combinations for efficiency\n",
    "- **Grid Search**: Performed on 20% sample, best params used for full training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLOps Integration\n\n",
    "### Experiment Tracking with MLflow\n\n",
    "This model integrates with MLflow for comprehensive experiment tracking:\n\n",
    "```python\n",
    "from lib.mlops.mlflow_tracker import create_mlflow_tracker\n",
    "\n",
    "# MLflow automatically tracks:\n",
    "# - Hyperparameters (learning_rate, batch_size, etc.)\n",
    "# - Metrics (train_loss, val_acc, test_f1, etc.)\n",
    "# - Model artifacts (checkpoints, configs)\n",
    "# - Run metadata (tags, timestamps, fold numbers)\n",
    "```\n\n",
    "**Access MLflow UI**:\n",
    "```bash\n",
    "mlflow ui --port 5000\n",
    "# Open http://localhost:5000\n",
    "```\n\n",
    "### DuckDB Analytics\n\n",
    "Query training results with SQL for fast analytics:\n\n",
    "```python\n",
    "from lib.utils.duckdb_analytics import DuckDBAnalytics\n",
    "\n",
    "analytics = DuckDBAnalytics()\n",
    "analytics.register_parquet('results', 'data/stage5/{model_type}/metrics.json')\n",
    "result = analytics.query(\"\"\"\n",
    "    SELECT \n",
    "        fold,\n",
    "        AVG(test_f1) as avg_f1,\n",
    "        STDDEV(test_f1) as std_f1\n",
    "    FROM results\n",
    "    GROUP BY fold\n",
    "\"\"\")\n",
    "```\n\n",
    "### Airflow Orchestration\n\n",
    "Pipeline orchestrated via Apache Airflow DAG (`airflow/dags/fvc_pipeline_dag.py`):\n",
    "- **Dependency Management**: Automatic task ordering\n",
    "- **Retry Logic**: Automatic retries on failure\n",
    "- **Monitoring**: Web UI for pipeline status\n",
    "- **Scheduling**: Cron-based scheduling support\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Methodology\n\n",
    "### 5-Fold Stratified Cross-Validation\n\n",
    "- **Purpose**: Robust performance estimates, prevents overfitting\n",
    "- **Stratification**: Ensures class balance in each fold\n",
    "- **Evaluation**: Metrics averaged across folds with standard deviation\n",
    "- **Rationale**: More reliable than single train/test split\n\n",
    "### Regularization Strategy\n\n",
    "- **Weight Decay (L2)**: 1e-4 (PyTorch models)\n",
    "- **Dropout**: 0.5 in classification heads (PyTorch models)\n",
    "- **Early Stopping**: Patience=5 epochs (prevents overfitting)\n",
    "- **Gradient Clipping**: max_norm=1.0 (prevents exploding gradients)\n",
    "- **Class Weights**: Balanced sampling for imbalanced datasets\n\n",
    "### Optimization\n\n",
    "- **Optimizer**: AdamW with betas=(0.9, 0.999)\n",
    "- **Mixed Precision**: AMP (Automatic Mixed Precision) for memory efficiency\n",
    "- **Gradient Accumulation**: Dynamic based on batch size (maintains effective batch size)\n",
    "- **Learning Rate Schedule**: Cosine annealing with warmup (2 epochs)\n",
    "- **Differential Learning Rates**: Lower LR for pretrained backbones (5e-6) vs heads (5e-4)\n\n",
    "### Data Pipeline\n\n",
    "- **Video Loading**: Frame-by-frame decoding (50x memory reduction)\n",
    "- **Augmentation**: Pre-generated augmentations (reproducible, fast)\n",
    "- **Scaling**: Fixed 256x256 max dimension with letterboxing\n",
    "- **Frame Sampling**: Uniform sampling across video duration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Rationale\n\n",
    "See master pipeline notebook (`00_MASTER_PIPELINE_JOURNEY.ipynb`) for comprehensive design rationale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture Deep-Dive\n\n",
    "**svm** architecture details.\n\n",
    "See model implementation in `lib/training/` for specific architecture code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Configuration\n\n",
    "**Training Hyperparameters** (from `lib/training/grid_search.py`):\n\n",
    "- **C**: [0.1, 1.0, 10.0] (grid search)\n",
    "- **kernel**: ['linear', 'rbf'] (grid search)\n",
    "\n**Rationale**:\n",
    "- **Single Hyperparameter Combination**: Reduced from multiple combinations for efficiency\n",
    "- **Grid Search**: Performed on 20% sample, best params used for full training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLOps Integration\n\n",
    "### Experiment Tracking with MLflow\n\n",
    "This model integrates with MLflow for comprehensive experiment tracking:\n\n",
    "```python\n",
    "from lib.mlops.mlflow_tracker import create_mlflow_tracker\n",
    "\n",
    "# MLflow automatically tracks:\n",
    "# - Hyperparameters (learning_rate, batch_size, etc.)\n",
    "# - Metrics (train_loss, val_acc, test_f1, etc.)\n",
    "# - Model artifacts (checkpoints, configs)\n",
    "# - Run metadata (tags, timestamps, fold numbers)\n",
    "```\n\n",
    "**Access MLflow UI**:\n",
    "```bash\n",
    "mlflow ui --port 5000\n",
    "# Open http://localhost:5000\n",
    "```\n\n",
    "### DuckDB Analytics\n\n",
    "Query training results with SQL for fast analytics:\n\n",
    "```python\n",
    "from lib.utils.duckdb_analytics import DuckDBAnalytics\n",
    "\n",
    "analytics = DuckDBAnalytics()\n",
    "analytics.register_parquet('results', 'data/stage5/{model_type}/metrics.json')\n",
    "result = analytics.query(\"\"\"\n",
    "    SELECT \n",
    "        fold,\n",
    "        AVG(test_f1) as avg_f1,\n",
    "        STDDEV(test_f1) as std_f1\n",
    "    FROM results\n",
    "    GROUP BY fold\n",
    "\"\"\")\n",
    "```\n\n",
    "### Airflow Orchestration\n\n",
    "Pipeline orchestrated via Apache Airflow DAG (`airflow/dags/fvc_pipeline_dag.py`):\n",
    "- **Dependency Management**: Automatic task ordering\n",
    "- **Retry Logic**: Automatic retries on failure\n",
    "- **Monitoring**: Web UI for pipeline status\n",
    "- **Scheduling**: Cron-based scheduling support\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Methodology\n\n",
    "### 5-Fold Stratified Cross-Validation\n\n",
    "- **Purpose**: Robust performance estimates, prevents overfitting\n",
    "- **Stratification**: Ensures class balance in each fold\n",
    "- **Evaluation**: Metrics averaged across folds with standard deviation\n",
    "- **Rationale**: More reliable than single train/test split\n\n",
    "### Regularization Strategy\n\n",
    "- **Weight Decay (L2)**: 1e-4 (PyTorch models)\n",
    "- **Dropout**: 0.5 in classification heads (PyTorch models)\n",
    "- **Early Stopping**: Patience=5 epochs (prevents overfitting)\n",
    "- **Gradient Clipping**: max_norm=1.0 (prevents exploding gradients)\n",
    "- **Class Weights**: Balanced sampling for imbalanced datasets\n\n",
    "### Optimization\n\n",
    "- **Optimizer**: AdamW with betas=(0.9, 0.999)\n",
    "- **Mixed Precision**: AMP (Automatic Mixed Precision) for memory efficiency\n",
    "- **Gradient Accumulation**: Dynamic based on batch size (maintains effective batch size)\n",
    "- **Learning Rate Schedule**: Cosine annealing with warmup (2 epochs)\n",
    "- **Differential Learning Rates**: Lower LR for pretrained backbones (5e-6) vs heads (5e-4)\n\n",
    "### Data Pipeline\n\n",
    "- **Video Loading**: Frame-by-frame decoding (50x memory reduction)\n",
    "- **Augmentation**: Pre-generated augmentations (reproducible, fast)\n",
    "- **Scaling**: Fixed 256x256 max dimension with letterboxing\n",
    "- **Frame Sampling**: Uniform sampling across video duration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Rationale\n\n",
    "See master pipeline notebook (`00_MASTER_PIPELINE_JOURNEY.ipynb`) for comprehensive design rationale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Video, display, HTML\n",
    "import json\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().absolute().parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from lib.training.model_factory import create_model\n",
    "from lib.mlops.config import RunConfig\n",
    "from lib.utils.paths import load_metadata_flexible\n",
    "from lib.training.metrics_utils import compute_classification_metrics\n",
    "\n",
    "# Configuration\n",
    "MODEL_TYPE = \"svm\"\n",
    "MODEL_DIR = project_root / \"data\" / \"stage5\" / MODEL_TYPE\n",
    "SCALED_METADATA_PATH = project_root / \"data\" / \"stage3\" / \"scaled_metadata.parquet\"\n",
    "FEATURES_STAGE2_PATH = project_root / \"data\" / \"stage2\" / \"features_metadata.parquet\"\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Model directory: {MODEL_DIR}\")\n",
    "print(f\"Model directory exists: {MODEL_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Saved Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_saved_models(model_dir: Path):\n",
    "    \"\"\"Check for saved model files in the model directory.\"\"\"\n",
    "    if not model_dir.exists():\n",
    "        print(f\"❌ Model directory does not exist: {model_dir}\")\n",
    "        return False, []\n",
    "    \n",
    "    # Check for fold directories\n",
    "    fold_dirs = sorted([d for d in model_dir.iterdir() if d.is_dir() and d.name.startswith(\"fold_\")])\n",
    "    \n",
    "    if not fold_dirs:\n",
    "        print(f\"❌ No fold directories found in {model_dir}\")\n",
    "        return False, []\n",
    "    \n",
    "    print(f\"✓ Found {len(fold_dirs)} fold(s)\")\n",
    "    \n",
    "    models_found = []\n",
    "    for fold_dir in fold_dirs:\n",
    "        # Check for joblib model file (sklearn models)\n",
    "        model_file = fold_dir / \"model.joblib\"\n",
    "        if model_file.exists():\n",
    "            models_found.append((fold_dir.name, model_file))\n",
    "            print(f\"  ✓ {fold_dir.name}: Found model.joblib\")\n",
    "        else:\n",
    "            print(f\"  ❌ {fold_dir.name}: No model.joblib found\")\n",
    "    \n",
    "    return len(models_found) > 0, models_found\n",
    "\n",
    "models_available, model_files = check_saved_models(MODEL_DIR)\n",
    "\n",
    "if not models_available:\n",
    "    print(\"\\n⚠️  No trained models found. Please train the model first using the instructions above.\")\n",
    "    print(f\"Expected location: {MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if models_available:\n",
    "    import joblib\n",
    "    \n",
    "    # Load the first available model\n",
    "    fold_name, model_path = model_files[0]\n",
    "    print(f\"Loading model from: {model_path}\")\n",
    "    \n",
    "    model = joblib.load(model_path)\n",
    "    print(f\"✓ Model loaded successfully from {fold_name}\")\n",
    "    print(f\"Model type: {type(model)}\")\n",
    "    \n",
    "    # Load metadata\n",
    "    scaled_df = load_metadata_flexible(str(SCALED_METADATA_PATH))\n",
    "    features_df = load_metadata_flexible(str(FEATURES_STAGE2_PATH))\n",
    "    \n",
    "    if scaled_df is not None and features_df is not None:\n",
    "        print(f\"\\n✓ Loaded {scaled_df.height} videos from scaled metadata\")\n",
    "        print(f\"✓ Loaded {features_df.height} feature rows from Stage 2\")\n",
    "        \n",
    "        # Get sample videos\n",
    "        sample_videos = scaled_df.head(5).to_pandas()\n",
    "        print(f\"\\nSample videos for demonstration:\")\n",
    "        print(sample_videos[[\"video_path\", \"label\"]].to_string())\n",
    "    else:\n",
    "        print(\"⚠️  Could not load metadata files\")\n",
    "else:\n",
    "    print(\"⚠️  Skipping model loading - no trained models found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Sample Videos and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if models_available and 'model' in locals() and 'sample_videos' in locals():\n",
    "    # Create a simple visualization\n",
    "    fig, axes = plt.subplots(1, min(3, len(sample_videos)), figsize=(15, 5))\n",
    "    if len(sample_videos) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, (ax, row) in enumerate(zip(axes, sample_videos.iterrows())):\n",
    "        video_path = project_root / row[1][\"video_path\"]\n",
    "        label = row[1][\"label\"]\n",
    "        \n",
    "        # Try to load and display video thumbnail\n",
    "        try:\n",
    "            import cv2\n",
    "            cap = cv2.VideoCapture(str(video_path))\n",
    "            if cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if ret:\n",
    "                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    ax.imshow(frame_rgb)\n",
    "                    ax.set_title(f\"{Path(video_path).name}\\nLabel: {label}\", fontsize=10)\n",
    "                cap.release()\n",
    "        except Exception as e:\n",
    "            ax.text(0.5, 0.5, f\"Video: {Path(video_path).name}\\nLabel: {label}\", \n",
    "                    ha='center', va='center', fontsize=12, transform=ax.transAxes)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nNote: To play videos in the notebook, use:\")\n",
    "    print(\"display(Video('path/to/video.mp4', embed=True, width=640, height=480))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if models_available:\n",
    "    # Try to load metrics from fold directory\n",
    "    fold_dir = model_files[0][0]\n",
    "    metrics_file = MODEL_DIR / fold_dir / \"metrics.json\"\n",
    "    \n",
    "    if metrics_file.exists():\n",
    "        with open(metrics_file, 'r') as f:\n",
    "            metrics = json.load(f)\n",
    "        \n",
    "        print(\"Model Performance Metrics:\")\n",
    "        print(\"=\" * 50)\n",
    "        for key, value in metrics.items():\n",
    "            if isinstance(value, (int, float)):\n",
    "                print(f\"{key}: {value:.4f}\")\n",
    "            else:\n",
    "                print(f\"{key}: {value}\")\n",
    "        \n",
    "        # Create visualization if metrics available\n",
    "        if 'accuracy' in metrics or 'f1_score' in metrics:\n",
    "            fig, ax = plt.subplots(figsize=(8, 6))\n",
    "            metric_names = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "            metric_values = [metrics.get(m, 0) for m in metric_names]\n",
    "            \n",
    "            bars = ax.bar(metric_names, metric_values, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n",
    "            ax.set_ylabel('Score')\n",
    "            ax.set_title('SVM Model Performance')\n",
    "            ax.set_ylim(0, 1)\n",
    "            \n",
    "            # Add value labels on bars\n",
    "            for bar, val in zip(bars, metric_values):\n",
    "                height = bar.get_height()\n",
    "                ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                       f'{val:.3f}', ha='center', va='bottom')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"⚠️  Metrics file not found. Model may not have been fully trained.\")\n",
    "        print(f\"Expected: {metrics_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture Summary\n",
    "\n",
    "**Support Vector Machine (SVM)** is a kernel-based classifier that:\n",
    "- Uses handcrafted features from Stage 2 (noise residual, DCT statistics, blur/sharpness, codec cues)\n",
    "- Supports linear and RBF kernels for non-linear decision boundaries\n",
    "- Finds optimal hyperplane to separate real vs fake videos\n",
    "- Outputs probability scores for binary classification\n",
    "\n",
    "**Advantages:**\n",
    "- Can capture non-linear patterns with RBF kernel\n",
    "- Effective for high-dimensional feature spaces\n",
    "- Good generalization with proper regularization\n",
    "\n",
    "**Limitations:**\n",
    "- Slower than logistic regression for large datasets\n",
    "- Requires careful kernel and hyperparameter selection\n",
    "- No temporal modeling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
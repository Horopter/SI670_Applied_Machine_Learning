{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5alpha: sklearn LogisticRegression\n",
    "\n",
    "This notebook demonstrates the sklearn LogisticRegression model for deepfake video detection.\n",
    "\n",
    "## Model Overview\n",
    "\n",
    "sklearn LogisticRegression with L1/L2/ElasticNet regularization. Uses handcrafted features from Stage 2/4. This is a standalone implementation separate from the pipeline's logistic regression.\n",
    "\n",
    "## Training Instructions\n",
    "\n",
    "To train this model, run:\n",
    "\n",
    "```bash\n",
    "sbatch src/scripts/slurm_stage5alpha.sh\n",
    "```\n",
    "\n",
    "Or use Python:\n",
    "\n",
    "```python\n",
    "from src.scripts.train_sklearn_logreg import train_sklearn_logreg\n",
    "\n",
    "results = train_sklearn_logreg(\n",
    "    project_root=\".\",\n",
    "    scaled_metadata_path=\"data/stage3/scaled_metadata.parquet\",\n",
    "    features_stage2_path=\"data/stage2/features_metadata.parquet\",\n",
    "    features_stage4_path=None,\n",
    "    output_dir=\"data/stage5/sklearn_logreg\",\n",
    "    n_splits=5,\n",
    "    delete_existing=False\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture Deep-Dive\n\n",
    "**sklearn_logreg** architecture details.\n\n",
    "See model implementation in `lib/training/` for specific architecture code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Configuration\n\n",
    "Hyperparameters configured in `lib/training/grid_search.py`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLOps Integration\n\n",
    "### Experiment Tracking with MLflow\n\n",
    "This model integrates with MLflow for comprehensive experiment tracking:\n\n",
    "```python\n",
    "from lib.mlops.mlflow_tracker import create_mlflow_tracker\n",
    "\n",
    "# MLflow automatically tracks:\n",
    "# - Hyperparameters (learning_rate, batch_size, etc.)\n",
    "# - Metrics (train_loss, val_acc, test_f1, etc.)\n",
    "# - Model artifacts (checkpoints, configs)\n",
    "# - Run metadata (tags, timestamps, fold numbers)\n",
    "```\n\n",
    "**Access MLflow UI**:\n",
    "```bash\n",
    "mlflow ui --port 5000\n",
    "# Open http://localhost:5000\n",
    "```\n\n",
    "### DuckDB Analytics\n\n",
    "Query training results with SQL for fast analytics:\n\n",
    "```python\n",
    "from lib.utils.duckdb_analytics import DuckDBAnalytics\n",
    "\n",
    "analytics = DuckDBAnalytics()\n",
    "analytics.register_parquet('results', 'data/stage5/{model_type}/metrics.json')\n",
    "result = analytics.query(\"\"\"\n",
    "    SELECT \n",
    "        fold,\n",
    "        AVG(test_f1) as avg_f1,\n",
    "        STDDEV(test_f1) as std_f1\n",
    "    FROM results\n",
    "    GROUP BY fold\n",
    "\"\"\")\n",
    "```\n\n",
    "### Airflow Orchestration\n\n",
    "Pipeline orchestrated via Apache Airflow DAG (`airflow/dags/fvc_pipeline_dag.py`):\n",
    "- **Dependency Management**: Automatic task ordering\n",
    "- **Retry Logic**: Automatic retries on failure\n",
    "- **Monitoring**: Web UI for pipeline status\n",
    "- **Scheduling**: Cron-based scheduling support\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Methodology\n\n",
    "### 5-Fold Stratified Cross-Validation\n\n",
    "- **Purpose**: Robust performance estimates, prevents overfitting\n",
    "- **Stratification**: Ensures class balance in each fold\n",
    "- **Evaluation**: Metrics averaged across folds with standard deviation\n",
    "- **Rationale**: More reliable than single train/test split\n\n",
    "### Regularization Strategy\n\n",
    "- **Weight Decay (L2)**: 1e-4 (PyTorch models)\n",
    "- **Dropout**: 0.5 in classification heads (PyTorch models)\n",
    "- **Early Stopping**: Patience=5 epochs (prevents overfitting)\n",
    "- **Gradient Clipping**: max_norm=1.0 (prevents exploding gradients)\n",
    "- **Class Weights**: Balanced sampling for imbalanced datasets\n\n",
    "### Optimization\n\n",
    "- **Optimizer**: AdamW with betas=(0.9, 0.999)\n",
    "- **Mixed Precision**: AMP (Automatic Mixed Precision) for memory efficiency\n",
    "- **Gradient Accumulation**: Dynamic based on batch size (maintains effective batch size)\n",
    "- **Learning Rate Schedule**: Cosine annealing with warmup (2 epochs)\n",
    "- **Differential Learning Rates**: Lower LR for pretrained backbones (5e-6) vs heads (5e-4)\n\n",
    "### Data Pipeline\n\n",
    "- **Video Loading**: Frame-by-frame decoding (50x memory reduction)\n",
    "- **Augmentation**: Pre-generated augmentations (reproducible, fast)\n",
    "- **Scaling**: Fixed 256x256 max dimension with letterboxing\n",
    "- **Frame Sampling**: Uniform sampling across video duration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Rationale\n\n",
    "See master pipeline notebook (`00_MASTER_PIPELINE_JOURNEY.ipynb`) for comprehensive design rationale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture Deep-Dive\n\n",
    "**sklearn_logreg** architecture details.\n\n",
    "See model implementation in `lib/training/` for specific architecture code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Configuration\n\n",
    "Hyperparameters configured in `lib/training/grid_search.py`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLOps Integration\n\n",
    "### Experiment Tracking with MLflow\n\n",
    "This model integrates with MLflow for comprehensive experiment tracking:\n\n",
    "```python\n",
    "from lib.mlops.mlflow_tracker import create_mlflow_tracker\n",
    "\n",
    "# MLflow automatically tracks:\n",
    "# - Hyperparameters (learning_rate, batch_size, etc.)\n",
    "# - Metrics (train_loss, val_acc, test_f1, etc.)\n",
    "# - Model artifacts (checkpoints, configs)\n",
    "# - Run metadata (tags, timestamps, fold numbers)\n",
    "```\n\n",
    "**Access MLflow UI**:\n",
    "```bash\n",
    "mlflow ui --port 5000\n",
    "# Open http://localhost:5000\n",
    "```\n\n",
    "### DuckDB Analytics\n\n",
    "Query training results with SQL for fast analytics:\n\n",
    "```python\n",
    "from lib.utils.duckdb_analytics import DuckDBAnalytics\n",
    "\n",
    "analytics = DuckDBAnalytics()\n",
    "analytics.register_parquet('results', 'data/stage5/{model_type}/metrics.json')\n",
    "result = analytics.query(\"\"\"\n",
    "    SELECT \n",
    "        fold,\n",
    "        AVG(test_f1) as avg_f1,\n",
    "        STDDEV(test_f1) as std_f1\n",
    "    FROM results\n",
    "    GROUP BY fold\n",
    "\"\"\")\n",
    "```\n\n",
    "### Airflow Orchestration\n\n",
    "Pipeline orchestrated via Apache Airflow DAG (`airflow/dags/fvc_pipeline_dag.py`):\n",
    "- **Dependency Management**: Automatic task ordering\n",
    "- **Retry Logic**: Automatic retries on failure\n",
    "- **Monitoring**: Web UI for pipeline status\n",
    "- **Scheduling**: Cron-based scheduling support\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Methodology\n\n",
    "### 5-Fold Stratified Cross-Validation\n\n",
    "- **Purpose**: Robust performance estimates, prevents overfitting\n",
    "- **Stratification**: Ensures class balance in each fold\n",
    "- **Evaluation**: Metrics averaged across folds with standard deviation\n",
    "- **Rationale**: More reliable than single train/test split\n\n",
    "### Regularization Strategy\n\n",
    "- **Weight Decay (L2)**: 1e-4 (PyTorch models)\n",
    "- **Dropout**: 0.5 in classification heads (PyTorch models)\n",
    "- **Early Stopping**: Patience=5 epochs (prevents overfitting)\n",
    "- **Gradient Clipping**: max_norm=1.0 (prevents exploding gradients)\n",
    "- **Class Weights**: Balanced sampling for imbalanced datasets\n\n",
    "### Optimization\n\n",
    "- **Optimizer**: AdamW with betas=(0.9, 0.999)\n",
    "- **Mixed Precision**: AMP (Automatic Mixed Precision) for memory efficiency\n",
    "- **Gradient Accumulation**: Dynamic based on batch size (maintains effective batch size)\n",
    "- **Learning Rate Schedule**: Cosine annealing with warmup (2 epochs)\n",
    "- **Differential Learning Rates**: Lower LR for pretrained backbones (5e-6) vs heads (5e-4)\n\n",
    "### Data Pipeline\n\n",
    "- **Video Loading**: Frame-by-frame decoding (50x memory reduction)\n",
    "- **Augmentation**: Pre-generated augmentations (reproducible, fast)\n",
    "- **Scaling**: Fixed 256x256 max dimension with letterboxing\n",
    "- **Frame Sampling**: Uniform sampling across video duration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Rationale\n\n",
    "See master pipeline notebook (`00_MASTER_PIPELINE_JOURNEY.ipynb`) for comprehensive design rationale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Video, display, HTML\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().absolute().parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from lib.utils.paths import load_metadata_flexible\n",
    "from lib.training.metrics_utils import compute_classification_metrics\n",
    "\n",
    "# Configuration\n",
    "MODEL_TYPE = \"sklearn_logreg\"\n",
    "MODEL_DIR = project_root / \"data\" / \"stage5\" / \"sklearn_logreg\"\n",
    "SCALED_METADATA_PATH = project_root / \"data\" / \"stage3\" / \"scaled_metadata.parquet\"\n",
    "FEATURES_STAGE2_PATH = project_root / \"data\" / \"stage2\" / \"features_metadata.parquet\"\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Model directory: {MODEL_DIR}\")\n",
    "print(f\"Model directory exists: {MODEL_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Saved Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_saved_models(model_dir: Path):\n",
    "    \"\"\"Check for saved sklearn model files.\"\"\"\n",
    "    if not model_dir.exists():\n",
    "        print(f\"\u274c Model directory does not exist: {model_dir}\")\n",
    "        return False, None\n",
    "    \n",
    "    # sklearn_logreg saves model directly in output_dir, not in fold subdirectories\n",
    "    model_file = model_dir / \"model.joblib\"\n",
    "    scaler_file = model_dir / \"scaler.joblib\"\n",
    "    metrics_file = model_dir / \"metrics.json\"\n",
    "    \n",
    "    if model_file.exists():\n",
    "        print(f\"\u2713 Found model.joblib\")\n",
    "        if scaler_file.exists():\n",
    "            print(f\"\u2713 Found scaler.joblib\")\n",
    "        if metrics_file.exists():\n",
    "            print(f\"\u2713 Found metrics.json\")\n",
    "        return True, model_file\n",
    "    else:\n",
    "        print(f\"\u274c No model.joblib found in {model_dir}\")\n",
    "        return False, None\n",
    "\n",
    "models_available, model_file = check_saved_models(MODEL_DIR)\n",
    "\n",
    "if not models_available:\n",
    "    print(\"\\n\u26a0\ufe0f  No trained models found. Please train the model first using the instructions above.\")\n",
    "    print(f\"Expected location: {MODEL_DIR / 'model.joblib'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if models_available:\n",
    "    print(f\"Loading model from: {model_file}\")\n",
    "    \n",
    "    model = joblib.load(model_file)\n",
    "    print(f\"\u2713 Model loaded successfully\")\n",
    "    print(f\"Model type: {type(model)}\")\n",
    "    \n",
    "    # Load scaler if available\n",
    "    scaler = None\n",
    "    scaler_file = MODEL_DIR / \"scaler.joblib\"\n",
    "    if scaler_file.exists():\n",
    "        scaler = joblib.load(scaler_file)\n",
    "        print(f\"\u2713 Scaler loaded\")\n",
    "    \n",
    "    # Load metadata\n",
    "    scaled_df = load_metadata_flexible(str(SCALED_METADATA_PATH))\n",
    "    features_df = load_metadata_flexible(str(FEATURES_STAGE2_PATH))\n",
    "    \n",
    "    if scaled_df is not None and features_df is not None:\n",
    "        print(f\"\\n\u2713 Loaded {scaled_df.height} videos from scaled metadata\")\n",
    "        print(f\"\u2713 Loaded {features_df.height} feature rows from Stage 2\")\n",
    "        \n",
    "        # Get sample videos\n",
    "        sample_videos = scaled_df.head(5).to_pandas()\n",
    "        print(f\"\\nSample videos for demonstration:\")\n",
    "        print(sample_videos[[\"video_path\", \"label\"]].to_string())\n",
    "    else:\n",
    "        print(\"\u26a0\ufe0f  Could not load metadata files\")\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f  Skipping model loading - no trained models found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Sample Videos and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if models_available and 'model' in locals() and 'sample_videos' in locals():\n",
    "    # Create a simple visualization\n",
    "    fig, axes = plt.subplots(1, min(3, len(sample_videos)), figsize=(15, 5))\n",
    "    if len(sample_videos) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, (ax, row) in enumerate(zip(axes, sample_videos.iterrows())):\n",
    "        video_path = project_root / row[1][\"video_path\"]\n",
    "        label = row[1][\"label\"]\n",
    "        \n",
    "        # Try to load and display video thumbnail\n",
    "        try:\n",
    "            import cv2\n",
    "            cap = cv2.VideoCapture(str(video_path))\n",
    "            if cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if ret:\n",
    "                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    ax.imshow(frame_rgb)\n",
    "                    ax.set_title(f\"{Path(video_path).name}\\nLabel: {label}\", fontsize=10)\n",
    "                cap.release()\n",
    "        except Exception as e:\n",
    "            ax.text(0.5, 0.5, f\"Video: {Path(video_path).name}\\nLabel: {label}\", \n",
    "                    ha='center', va='center', fontsize=12, transform=ax.transAxes)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nNote: To play videos in the notebook, use:\")\n",
    "    print(\"display(Video('path/to/video.mp4', embed=True, width=640, height=480))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if models_available:\n",
    "    # Try to load metrics from model directory\n",
    "    metrics_file = MODEL_DIR / \"metrics.json\"\n",
    "    \n",
    "    if metrics_file.exists():\n",
    "        with open(metrics_file, 'r') as f:\n",
    "            metrics = json.load(f)\n",
    "        \n",
    "        print(\"Model Performance Metrics:\")\n",
    "        print(\"=\" * 50)\n",
    "        for key, value in metrics.items():\n",
    "            if isinstance(value, (int, float)):\n",
    "                print(f\"{key}: {value:.4f}\")\n",
    "            else:\n",
    "                print(f\"{key}: {value}\")\n",
    "        \n",
    "        # Create visualization if metrics available\n",
    "        if 'test_f1' in metrics or 'test_accuracy' in metrics:\n",
    "            fig, ax = plt.subplots(figsize=(8, 6))\n",
    "            metric_names = ['test_accuracy', 'test_precision', 'test_recall', 'test_f1']\n",
    "            metric_values = [metrics.get(m, 0) for m in metric_names]\n",
    "            \n",
    "            bars = ax.bar(metric_names, metric_values, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n",
    "            ax.set_ylabel('Score')\n",
    "            ax.set_title('sklearn LogisticRegression Model Performance')\n",
    "            ax.set_ylim(0, 1)\n",
    "            \n",
    "            # Add value labels on bars\n",
    "            for bar, val in zip(bars, metric_values):\n",
    "                height = bar.get_height()\n",
    "                ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                       f'{val:.3f}', ha='center', va='bottom')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"\u26a0\ufe0f  Metrics file not found. Model may not have been fully trained.\")\n",
    "        print(f\"Expected: {metrics_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture Summary\n",
    "\n",
    "**sklearn LogisticRegression** is a linear classifier that:\n",
    "- Uses handcrafted features from Stage 2 (noise residual, DCT statistics, blur/sharpness, codec cues)\n",
    "- Supports L1, L2, and ElasticNet regularization\n",
    "- Uses StandardScaler for feature normalization\n",
    "- Outputs probability scores for binary classification (real vs fake)\n",
    "- Trained with grid search on hyperparameters (C, penalty, solver)\n",
    "\n",
    "**Advantages:**\n",
    "- Simple and interpretable\n",
    "- Fast training and inference\n",
    "- Multiple regularization options (L1/L2/ElasticNet)\n",
    "- Good baseline for comparison\n",
    "\n",
    "**Limitations:**\n",
    "- Linear decision boundary (may not capture complex patterns)\n",
    "- Relies on quality of handcrafted features\n",
    "- No temporal modeling\n",
    "\n",
    "**Difference from 5a:** This is a standalone sklearn implementation with more regularization options, while 5a uses the pipeline's LogisticRegressionBaseline class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model 5beta: Gradient Boosting Models\n",
        "\n",
        "This notebook demonstrates the Gradient Boosting models (XGBoost, LightGBM, CatBoost) for deepfake video detection.\n",
        "\n",
        "## Model Overview\n",
        "\n",
        "Gradient Boosting models (XGBoost, LightGBM, CatBoost) trained on handcrafted features from Stage 2/4. These are tree-based ensemble methods that can capture non-linear patterns.\n",
        "\n",
        "## Training Instructions\n",
        "\n",
        "To train these models, run:\n",
        "\n",
        "```bash\n",
        "sbatch scripts/slurm_jobs/slurm_stage5beta.sh\n",
        "```\n",
        "\n",
        "Or use Python:\n",
        "\n",
        "```python\n",
        "from src.scripts.train_gradient_boosting import train_gradient_boosting\n",
        "\n",
        "results = train_gradient_boosting(\n",
        "    project_root=\".\",\n",
        "    scaled_metadata_path=\"data/stage3/scaled_metadata.parquet\",\n",
        "    features_stage2_path=\"data/stage2/features_metadata.parquet\",\n",
        "    features_stage4_path=None,\n",
        "    output_dir=\"data/stage5\",\n",
        "    n_splits=5,\n",
        "    models=[\"xgboost\", \"lightgbm\", \"catboost\"],\n",
        "    delete_existing=False\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Architecture Deep-Dive\n",
        "\n",
        "**gradient_boosting** architecture details.\n",
        "\n",
        "See model implementation in `lib/training/` for specific architecture code.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyperparameter Configuration\n",
        "\n",
        "Hyperparameters configured in `lib/training/grid_search.py`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MLOps Integration\n",
        "\n",
        "### Experiment Tracking with MLflow\n",
        "\n",
        "This model integrates with MLflow for comprehensive experiment tracking:\n",
        "\n",
        "```python\n",
        "from lib.mlops.mlflow_tracker import create_mlflow_tracker\n",
        "\n",
        "# MLflow automatically tracks:\n",
        "# - Hyperparameters (learning_rate, batch_size, etc.)\n",
        "# - Metrics (train_loss, val_acc, test_f1, etc.)\n",
        "# - Model artifacts (checkpoints, configs)\n",
        "# - Run metadata (tags, timestamps, fold numbers)\n",
        "```\n",
        "\n",
        "**Access MLflow UI**:\n",
        "```bash\n",
        "mlflow ui --port 5000\n",
        "# Open http://localhost:5000\n",
        "```\n",
        "\n",
        "### DuckDB Analytics\n",
        "\n",
        "Query training results with SQL for fast analytics:\n",
        "\n",
        "```python\n",
        "from lib.utils.duckdb_analytics import DuckDBAnalytics\n",
        "\n",
        "analytics = DuckDBAnalytics()\n",
        "analytics.register_parquet('results', 'data/stage5/{model_type}/metrics.json')\n",
        "result = analytics.query(\"\"\"\n",
        "    SELECT \n",
        "        fold,\n",
        "        AVG(test_f1) as avg_f1,\n",
        "        STDDEV(test_f1) as std_f1\n",
        "    FROM results\n",
        "    GROUP BY fold\n",
        "\"\"\")\n",
        "```\n",
        "\n",
        "### Airflow Orchestration\n",
        "\n",
        "Pipeline orchestrated via Apache Airflow DAG (`airflow/dags/fvc_pipeline_dag.py`):\n",
        "- **Dependency Management**: Automatic task ordering\n",
        "- **Retry Logic**: Automatic retries on failure\n",
        "- **Monitoring**: Web UI for pipeline status\n",
        "- **Scheduling**: Cron-based scheduling support\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Methodology\n",
        "\n",
        "### 5-Fold Stratified Cross-Validation\n",
        "\n",
        "- **Purpose**: Robust performance estimates, prevents overfitting\n",
        "- **Stratification**: Ensures class balance in each fold\n",
        "- **Evaluation**: Metrics averaged across folds with standard deviation\n",
        "- **Rationale**: More reliable than single train/test split\n",
        "\n",
        "### Regularization Strategy\n",
        "\n",
        "- **Weight Decay (L2)**: 1e-4 (PyTorch models)\n",
        "- **Dropout**: 0.5 in classification heads (PyTorch models)\n",
        "- **Early Stopping**: Patience=5 epochs (prevents overfitting)\n",
        "- **Gradient Clipping**: max_norm=1.0 (prevents exploding gradients)\n",
        "- **Class Weights**: Balanced sampling for imbalanced datasets\n",
        "\n",
        "### Optimization\n",
        "\n",
        "- **Optimizer**: AdamW with betas=(0.9, 0.999)\n",
        "- **Mixed Precision**: AMP (Automatic Mixed Precision) for memory efficiency\n",
        "- **Gradient Accumulation**: Dynamic based on batch size (maintains effective batch size)\n",
        "- **Learning Rate Schedule**: Cosine annealing with warmup (2 epochs)\n",
        "- **Differential Learning Rates**: Lower LR for pretrained backbones (5e-6) vs heads (5e-4)\n",
        "\n",
        "### Data Pipeline\n",
        "\n",
        "- **Video Loading**: Frame-by-frame decoding (50x memory reduction)\n",
        "- **Augmentation**: Pre-generated augmentations (reproducible, fast)\n",
        "- **Scaling**: Fixed 256x256 max dimension with letterboxing\n",
        "- **Frame Sampling**: Uniform sampling across video duration\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Design Rationale\n",
        "\n",
        "See master pipeline notebook (`00_MASTER_PIPELINE_JOURNEY.ipynb`) for comprehensive design rationale.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Architecture Deep-Dive\n",
        "\n",
        "**gradient_boosting** architecture details.\n",
        "\n",
        "See model implementation in `lib/training/` for specific architecture code.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyperparameter Configuration\n",
        "\n",
        "Hyperparameters configured in `lib/training/grid_search.py`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MLOps Integration\n",
        "\n",
        "### Experiment Tracking with MLflow\n",
        "\n",
        "This model integrates with MLflow for comprehensive experiment tracking:\n",
        "\n",
        "```python\n",
        "from lib.mlops.mlflow_tracker import create_mlflow_tracker\n",
        "\n",
        "# MLflow automatically tracks:\n",
        "# - Hyperparameters (learning_rate, batch_size, etc.)\n",
        "# - Metrics (train_loss, val_acc, test_f1, etc.)\n",
        "# - Model artifacts (checkpoints, configs)\n",
        "# - Run metadata (tags, timestamps, fold numbers)\n",
        "```\n",
        "\n",
        "**Access MLflow UI**:\n",
        "```bash\n",
        "mlflow ui --port 5000\n",
        "# Open http://localhost:5000\n",
        "```\n",
        "\n",
        "### DuckDB Analytics\n",
        "\n",
        "Query training results with SQL for fast analytics:\n",
        "\n",
        "```python\n",
        "from lib.utils.duckdb_analytics import DuckDBAnalytics\n",
        "\n",
        "analytics = DuckDBAnalytics()\n",
        "analytics.register_parquet('results', 'data/stage5/{model_type}/metrics.json')\n",
        "result = analytics.query(\"\"\"\n",
        "    SELECT \n",
        "        fold,\n",
        "        AVG(test_f1) as avg_f1,\n",
        "        STDDEV(test_f1) as std_f1\n",
        "    FROM results\n",
        "    GROUP BY fold\n",
        "\"\"\")\n",
        "```\n",
        "\n",
        "### Airflow Orchestration\n",
        "\n",
        "Pipeline orchestrated via Apache Airflow DAG (`airflow/dags/fvc_pipeline_dag.py`):\n",
        "- **Dependency Management**: Automatic task ordering\n",
        "- **Retry Logic**: Automatic retries on failure\n",
        "- **Monitoring**: Web UI for pipeline status\n",
        "- **Scheduling**: Cron-based scheduling support\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Methodology\n",
        "\n",
        "### 5-Fold Stratified Cross-Validation\n",
        "\n",
        "- **Purpose**: Robust performance estimates, prevents overfitting\n",
        "- **Stratification**: Ensures class balance in each fold\n",
        "- **Evaluation**: Metrics averaged across folds with standard deviation\n",
        "- **Rationale**: More reliable than single train/test split\n",
        "\n",
        "### Regularization Strategy\n",
        "\n",
        "- **Weight Decay (L2)**: 1e-4 (PyTorch models)\n",
        "- **Dropout**: 0.5 in classification heads (PyTorch models)\n",
        "- **Early Stopping**: Patience=5 epochs (prevents overfitting)\n",
        "- **Gradient Clipping**: max_norm=1.0 (prevents exploding gradients)\n",
        "- **Class Weights**: Balanced sampling for imbalanced datasets\n",
        "\n",
        "### Optimization\n",
        "\n",
        "- **Optimizer**: AdamW with betas=(0.9, 0.999)\n",
        "- **Mixed Precision**: AMP (Automatic Mixed Precision) for memory efficiency\n",
        "- **Gradient Accumulation**: Dynamic based on batch size (maintains effective batch size)\n",
        "- **Learning Rate Schedule**: Cosine annealing with warmup (2 epochs)\n",
        "- **Differential Learning Rates**: Lower LR for pretrained backbones (5e-6) vs heads (5e-4)\n",
        "\n",
        "### Data Pipeline\n",
        "\n",
        "- **Video Loading**: Frame-by-frame decoding (50x memory reduction)\n",
        "- **Augmentation**: Pre-generated augmentations (reproducible, fast)\n",
        "- **Scaling**: Fixed 256x256 max dimension with letterboxing\n",
        "- **Frame Sampling**: Uniform sampling across video duration\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Design Rationale\n",
        "\n",
        "See master pipeline notebook (`00_MASTER_PIPELINE_JOURNEY.ipynb`) for comprehensive design rationale.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import Video, display, HTML\n",
        "import json\n",
        "import joblib\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path().absolute().parent.parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "from lib.utils.paths import load_metadata_flexible\n",
        "from lib.training.metrics_utils import compute_classification_metrics\n",
        "\n",
        "# Configuration\n",
        "BASE_MODEL_DIR = project_root / \"data\" / \"stage5\"\n",
        "SCALED_METADATA_PATH = project_root / \"data\" / \"stage3\" / \"scaled_metadata.parquet\"\n",
        "FEATURES_STAGE2_PATH = project_root / \"data\" / \"stage2\" / \"features_metadata.parquet\"\n",
        "\n",
        "# Available models\n",
        "MODELS = [\"xgboost\", \"lightgbm\", \"catboost\"]\n",
        "\n",
        "print(f\"Project root: {project_root}\")\n",
        "print(f\"Base model directory: {BASE_MODEL_DIR}\")\n",
        "print(f\"Base model directory exists: {BASE_MODEL_DIR.exists()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check for Saved Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_saved_models(base_dir: Path, model_names: list):\n",
        "    \"\"\"Check for saved gradient boosting model files.\"\"\"\n",
        "    available_models = {}\n",
        "    \n",
        "    for model_name in model_names:\n",
        "        model_dir = base_dir / model_name\n",
        "        \n",
        "        if not model_dir.exists():\n",
        "            print(f\"[X] {model_name}: Model directory does not exist: {model_dir}\")\n",
        "            continue\n",
        "        \n",
        "        # Different models save in different formats\n",
        "        if model_name == \"xgboost\":\n",
        "            model_file = model_dir / \"model.json\"\n",
        "        elif model_name == \"lightgbm\":\n",
        "            model_file = model_dir / \"model.joblib\"\n",
        "        elif model_name == \"catboost\":\n",
        "            model_file = model_dir / \"model.cbm\"\n",
        "        else:\n",
        "            model_file = model_dir / \"model.joblib\"  # Default\n",
        "        \n",
        "        metrics_file = model_dir / \"metrics.json\"\n",
        "        \n",
        "        if model_file.exists():\n",
        "            print(f\"[OK] {model_name}: Found {model_file.name}\")\n",
        "            if metrics_file.exists():\n",
        "                print(f\"  [OK] {model_name}: Found metrics.json\")\n",
        "            available_models[model_name] = model_file\n",
        "        else:\n",
        "            print(f\"[X] {model_name}: No model file found in {model_dir}\")\n",
        "    \n",
        "    return len(available_models) > 0, available_models\n",
        "\n",
        "models_available, model_files = check_saved_models(BASE_MODEL_DIR, MODELS)\n",
        "\n",
        "if not models_available:\n",
        "    print(\"\\n[WARN]  No trained models found. Please train the models first using the instructions above.\")\n",
        "    print(f\"Expected locations:\")\n",
        "    for model_name in MODELS:\n",
        "        print(f\"  - {BASE_MODEL_DIR / model_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loaded_models = {}\n",
        "\n",
        "if models_available:\n",
        "    # Try to import gradient boosting libraries\n",
        "    try:\n",
        "        XGBOOST_AVAILABLE = True\n",
        "    except ImportError:\n",
        "        XGBOOST_AVAILABLE = False\n",
        "        print(\"[WARN]  XGBoost not available\")\n",
        "    \n",
        "        LIGHTGBM_AVAILABLE = True\n",
        "    except ImportError:\n",
        "        LIGHTGBM_AVAILABLE = False\n",
        "        print(\"[WARN]  LightGBM not available\")\n",
        "    \n",
        "        CATBOOST_AVAILABLE = True\n",
        "    except ImportError:\n",
        "        CATBOOST_AVAILABLE = False\n",
        "        print(\"[WARN]  CatBoost not available\")\n",
        "    \n",
        "    # Load each available model\n",
        "    for model_name, model_file in model_files.items():\n",
        "        try:\n",
        "            if model_name == \"xgboost\" and XGBOOST_AVAILABLE:\n",
        "                model = xgb.Booster()\n",
        "                model.load_model(str(model_file))\n",
        "                loaded_models[model_name] = model\n",
        "                print(f\"[OK] Loaded {model_name} model\")\n",
        "            elif model_name == \"lightgbm\" and LIGHTGBM_AVAILABLE:\n",
        "                model = joblib.load(model_file)\n",
        "                loaded_models[model_name] = model\n",
        "                print(f\"[OK] Loaded {model_name} model\")\n",
        "            elif model_name == \"catboost\" and CATBOOST_AVAILABLE:\n",
        "                model = cb.CatBoostClassifier()\n",
        "                model.load_model(str(model_file))\n",
        "                loaded_models[model_name] = model\n",
        "                print(f\"[OK] Loaded {model_name} model\")\n",
        "        except Exception as e:\n",
        "            print(f\"[WARN] Error loading {model_name}: {e}\")\n",
        "    \n",
        "    # Load metadata\n",
        "    scaled_df = load_metadata_flexible(str(SCALED_METADATA_PATH))\n",
        "    features_df = load_metadata_flexible(str(FEATURES_STAGE2_PATH))\n",
        "    \n",
        "    if scaled_df is not None and features_df is not None:\n",
        "        print(f\"\\n[OK] Loaded {scaled_df.height} videos from scaled metadata\")\n",
        "        print(f\"[OK] Loaded {features_df.height} feature rows from Stage 2\")\n",
        "        \n",
        "        # Get sample videos\n",
        "        sample_videos = scaled_df.head(5).to_pandas()\n",
        "        print(f\"\\nSample videos for demonstration:\")\n",
        "        print(sample_videos[[\"video_path\", \"label\"]].to_string())\n",
        "    else:\n",
        "        print(\"[WARN]  Could not load metadata files\")\n",
        "else:\n",
        "    print(\"[WARN]  Skipping model loading - no trained models found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Display Sample Videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if models_available and 'sample_videos' in locals():\n",
        "    fig, axes = plt.subplots(1, min(3, len(sample_videos)), figsize=(15, 5))\n",
        "    if len(sample_videos) == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    for idx, (ax, row) in enumerate(zip(axes, sample_videos.iterrows())):\n",
        "        video_path = project_root / row[1][\"video_path\"]\n",
        "        label = row[1][\"label\"]\n",
        "        \n",
        "        try:\n",
        "            cap = cv2.VideoCapture(str(video_path))\n",
        "            if cap.isOpened():\n",
        "                ret, frame = cap.read()\n",
        "                if ret:\n",
        "                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                    ax.imshow(frame_rgb)\n",
        "                    ax.set_title(f\"{Path(video_path).name}\\nLabel: {label}\", fontsize=10)\n",
        "                cap.release()\n",
        "        except Exception as e:\n",
        "            ax.text(0.5, 0.5, f\"Video: {Path(video_path).name}\\nLabel: {label}\", \n",
        "                    ha='center', va='center', fontsize=12, transform=ax.transAxes)\n",
        "        ax.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\nNote: To play videos in the notebook, use:\")\n",
        "    print(\"display(Video('path/to/video.mp4', embed=True, width=640, height=480))\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Performance Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if models_available:\n",
        "    all_metrics = {}\n",
        "    \n",
        "    # Load metrics for each model\n",
        "    for model_name in model_files.keys():\n",
        "        model_dir = BASE_MODEL_DIR / model_name\n",
        "        metrics_file = model_dir / \"metrics.json\"\n",
        "        \n",
        "        if metrics_file.exists():\n",
        "            with open(metrics_file, 'r') as f:\n",
        "                metrics = json.load(f)\n",
        "            all_metrics[model_name] = metrics\n",
        "            \n",
        "            print(f\"\\n{model_name.upper()} Performance Metrics:\")\n",
        "            print(\"=\" * 50)\n",
        "            for key, value in metrics.items():\n",
        "                if isinstance(value, (int, float)):\n",
        "                    print(f\"  {key}: {value:.4f}\")\n",
        "    \n",
        "    # Create comparison visualization if multiple models available\n",
        "    if len(all_metrics) > 1:\n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "        \n",
        "        metric_names = ['test_accuracy', 'test_precision', 'test_recall', 'test_f1']\n",
        "        x = np.arange(len(metric_names))\n",
        "        width = 0.25\n",
        "        \n",
        "        for idx, (model_name, metrics) in enumerate(all_metrics.items()):\n",
        "            values = [metrics.get(m, 0) for m in metric_names]\n",
        "            offset = (idx - len(all_metrics) / 2) * width + width / 2\n",
        "            ax.bar(x + offset, values, width, label=model_name.upper())\n",
        "        \n",
        "        ax.set_ylabel('Score')\n",
        "        ax.set_title('Gradient Boosting Models Performance Comparison')\n",
        "        ax.set_xticks(x)\n",
        "        ax.set_xticklabels(metric_names)\n",
        "        ax.legend()\n",
        "        ax.set_ylim(0, 1)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    elif len(all_metrics) == 1:\n",
        "        # Single model visualization\n",
        "        model_name = list(all_metrics.keys())[0]\n",
        "        metrics = all_metrics[model_name]\n",
        "        \n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "        metric_names = ['test_accuracy', 'test_precision', 'test_recall', 'test_f1']\n",
        "        metric_values = [metrics.get(m, 0) for m in metric_names]\n",
        "        \n",
        "        bars = ax.bar(metric_names, metric_values, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n",
        "        ax.set_ylabel('Score')\n",
        "        ax.set_title(f'{model_name.upper()} Model Performance')\n",
        "        ax.set_ylim(0, 1)\n",
        "        \n",
        "        for bar, val in zip(bars, metric_values):\n",
        "            height = bar.get_height()\n",
        "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                   f'{val:.3f}', ha='center', va='bottom')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Plots\n",
        "\n",
        "The following plots were generated during model training and provide insights into model performance across cross-validation folds and hyperparameter search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display training plots if available\n",
        "from IPython.display import Image, display, HTML\n",
        "\n",
        "plots_dir = MODEL_DIR / \"plots\"\n",
        "\n",
        "if plots_dir.exists():\n",
        "    print(f\"[OK] Found plots directory: {plots_dir}\")\n",
        "    \n",
        "    # List of expected plot files\n",
        "    plot_files = {\n",
        "        \"cv_fold_comparison.png\": \"Cross-Validation Fold Comparison\",\n",
        "        \"hyperparameter_search.png\": \"Hyperparameter Search Results\",\n",
        "        \"learning_curves.png\": \"Learning Curves (if available)\",\n",
        "        \"roc_curve.png\": \"ROC Curve (if available)\",\n",
        "        \"precision_recall_curve.png\": \"Precision-Recall Curve (if available)\",\n",
        "        \"confusion_matrix.png\": \"Confusion Matrix (if available)\"\n",
        "    }\n",
        "    \n",
        "    plots_found = []\n",
        "    for plot_file, plot_name in plot_files.items():\n",
        "        plot_path = plots_dir / plot_file\n",
        "        if plot_path.exists():\n",
        "            plots_found.append((plot_path, plot_name))\n",
        "            print(f\"  [OK] Found: {plot_file}\")\n",
        "    \n",
        "    if plots_found:\n",
        "        print(f\"\\n[PLOT] Displaying {len(plots_found)} training plot(s):\\n\")\n",
        "        for plot_path, plot_name in plots_found:\n",
        "            print(f\"\\n### {plot_name}\")\n",
        "            display(Image(str(plot_path), width=800))\n",
        "    else:\n",
        "        print(\"[WARN]  No plot files found in plots directory.\")\n",
        "        print(f\"Expected plots directory: {plots_dir}\")\n",
        "else:\n",
        "    print(f\"[WARN]  Plots directory not found: {plots_dir}\")\n",
        "    print(\"Plots are generated during training. Please ensure training has completed successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Architecture Summary\n",
        "\n",
        "**Gradient Boosting Models** are tree-based ensemble methods:\n",
        "\n",
        "### XGBoost\n",
        "- Extreme Gradient Boosting with regularization\n",
        "- Uses handcrafted features from Stage 2/4\n",
        "- Handles missing values, supports parallel processing\n",
        "- Saves model as JSON format\n",
        "\n",
        "### LightGBM\n",
        "- Microsoft's gradient boosting framework\n",
        "- Uses leaf-wise tree growth for efficiency\n",
        "- Faster training than XGBoost on large datasets\n",
        "- Saves model as joblib format\n",
        "\n",
        "### CatBoost\n",
        "- Yandex's gradient boosting framework\n",
        "- Handles categorical features automatically\n",
        "- Robust to overfitting\n",
        "- Saves model as .cbm format\n",
        "\n",
        "**Advantages:**\n",
        "- Can capture non-linear patterns and feature interactions\n",
        "- Good performance on tabular data (handcrafted features)\n",
        "- Fast inference time\n",
        "- Interpretable feature importance\n",
        "\n",
        "**Limitations:**\n",
        "- Require feature engineering (handcrafted features)\n",
        "- No temporal modeling (treats features as independent)\n",
        "- May overfit on small datasets\n",
        "\n",
        "**Difference from 5f-5j:** These models use handcrafted features directly, while 5f-5j use deep learning features extracted from pretrained video models."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
